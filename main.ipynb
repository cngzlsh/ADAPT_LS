{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fb37f24",
   "metadata": {},
   "source": [
    "## Improving Lexical Simplification Using State of the Art Lexical Complexity Prediction Models\n",
    "#### Demo notebook\n",
    "This notebook provides a demonstration of simplifying sentence with multi-word expressions. It is tested on a system with the following specifications:\n",
    "<ol>\n",
    "    <li>OS: Linux x86-64</li>\n",
    "    <li>CPU: 3.30 Ghz x 8</li>\n",
    "    <li>RAM: 40 GiB</li>\n",
    "    <li>Hard Drive: 20 GiB</li>\n",
    "    <li>GPU: NVIDIA Corporation GA104M (CUDA compute capability: 8.6)</li>\n",
    " </ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0c1768",
   "metadata": {},
   "source": [
    "#### Run the following two cells to import packages and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c293036",
   "metadata": {},
   "outputs": [],
   "source": [
    " # imports\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import codecs\n",
    "\n",
    "from CWIs.complex_labeller import Complexity_labeller\n",
    "from plainifier.plainify import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9d16d90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 15:49:58.324608: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-03 15:49:58.325438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-03 15:49:58.325902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-03 15:49:58.326033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-03 15:50:00.732433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-03 15:50:00.732587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-03 15:50:00.732723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-03 15:50:00.732848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7982 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# settings\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "two_gram_mwes_list = './CWIs/2_gram_mwe_50.txt'\n",
    "three_gram_mwes_list = './CWIs/3_gram_mwe_25.txt'\n",
    "four_gram_mwes_list = './CWIs/4_gram_mwe_8.txt'\n",
    "pretrained_model_path = './CWIs/cwi_seq.model'\n",
    "temp_path = './CWIs/temp_file.txt'\n",
    "\n",
    "path = './plainifier/'\n",
    "premodel = 'bert-large-uncased-whole-word-masking'\n",
    "bert_dict = 'tersebert_pytorch_1_0.bin'\n",
    "embedding = 'crawl-300d-2M-subword.vec'\n",
    "unigram = 'unigrams-df.tsv'\n",
    "tokenizer = BertTokenizer.from_pretrained(premodel)\n",
    "Complexity_labeller_model = Complexity_labeller(pretrained_model_path, temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19f06e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 2000000/2000000 [01:30<00:00, 22001.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Embeddings\n",
      "Loading Unigrams\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 8394369/8394369 [05:53<00:00, 23747.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Unigrams\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# loading bert model, word embeddings and unigrams. This process takes 7 minutes\n",
    "model, similm, tokenfreq, embeddings, vocabulary2 = load_all(path, premodel, bert_dict, embedding, unigram, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792a5460",
   "metadata": {},
   "source": [
    "#### Run the following cell to construct the sentence class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a3e7d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexSentence:\n",
    "    # Sentence class\n",
    "    def __init__(self, sentence, label_model, tokeniser, verbose=True, beam_width=3):\n",
    "        self.sentence = sentence\n",
    "        self.tokenised_sentence = self.generate_tokenised_sentence()\n",
    "#         self.tokenised_sentence = tokeniser.tokenize(self.sentence)\n",
    "        self.label_model = label_model\n",
    "        self.verbose = verbose\n",
    "        self.beam_width = beam_width\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f'Untokenised sentence: {self.sentence}')\n",
    "            print(f'Tokenised sentence: {self.tokenised_sentence}')\n",
    "\n",
    "        self.label_complex_words()\n",
    "    \n",
    "    def generate_tokenised_sentence(self):\n",
    "        tokens = tokeniseUntokenise(self.sentence, tokenizer)['tokens']\n",
    "        word_idx = tokeniseUntokenise(self.sentence, tokenizer)['words']\n",
    "        tokenised_sentence_list = []\n",
    "        for idx_list in word_idx:\n",
    "            if len(idx_list)==1:\n",
    "                tokenised_sentence_list.append(np.array(tokens)[idx_list[0]])\n",
    "            else:\n",
    "                word_untokenised = ''\n",
    "                for idx_list_untokenised in idx_list:\n",
    "                    word_untokenised += np.array(tokens)[idx_list_untokenised].replace('##', '')\n",
    "                tokenised_sentence_list.append(word_untokenised)\n",
    "        return tokenised_sentence_list\n",
    "    \n",
    "    def known_complexity(self):\n",
    "        tokens = tokeniseUntokenise(self.sentence, tokenizer)['tokens']\n",
    "        word_idx = tokeniseUntokenise(self.sentence, tokenizer)['words']\n",
    "        known_index = []\n",
    "        for idx_list in word_idx:\n",
    "            if len(idx_list)==1 and not re.match(r'^[_\\W]+$', tokens[idx_list[0]]):\n",
    "                #If known label as True\n",
    "                known_index.append(True)\n",
    "            else:\n",
    "                #If unknown label as False\n",
    "                known_index.append(False)\n",
    "        return known_index\n",
    "    \n",
    "    def label_complex_words(self, init=True):\n",
    "        # applying complexity labeller to the sentence\n",
    "\n",
    "        Complexity_labeller.convert_format_string(self.label_model, self.sentence)\n",
    "        if init:\n",
    "            self.bin_labels = Complexity_labeller.get_bin_labels(self.label_model)[0]\n",
    "\n",
    "        # override complexity\n",
    "        self.bin_labels = np.multiply(self.bin_labels,self.known_complexity())\n",
    "\n",
    "        self.is_complex = True if np.sum(self.bin_labels) >= 1 else False\n",
    "        self.probs = Complexity_labeller.get_prob_labels(self.label_model)\n",
    "\n",
    "        # override complexity\n",
    "        self.probs = np.multiply(self.probs,self.known_complexity())\n",
    "\n",
    "        self.complexity_ranking = np.argsort(np.array(self.bin_labels) * np.array(self.probs))[::-1]\n",
    "        self.most_complex_word = self.tokenised_sentence[self.complexity_ranking[0]]\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f'Complex probs: {self.probs}')\n",
    "            print(f'Binary complexity labels: {self.bin_labels}')\n",
    "\n",
    "            if self.is_complex:\n",
    "                print(f'\\t Most complex word: {self.most_complex_word} \\n')\n",
    "\n",
    "        if not self.is_complex:\n",
    "            print(f'\\t Simplificaiton complete or no complex expression found.\\n')\n",
    "    \n",
    "    def find_MWEs_w_most_complex_word(self, n_gram, filepath):\n",
    "        # finds the n-gram mwe of the most complex word in the sentence, if any\n",
    "        # returns: mwe positions or complex word positions\n",
    "        \n",
    "        complex_word_pos = self.complexity_ranking[0]\n",
    "\n",
    "        if complex_word_pos - n_gram + 1 > 0:\n",
    "            sliding_start = complex_word_pos - n_gram + 1\n",
    "        else:\n",
    "            sliding_start = 0\n",
    "        \n",
    "        if complex_word_pos + n_gram - 1 < len(self.complexity_ranking):\n",
    "            sliding_end = complex_word_pos\n",
    "        else:\n",
    "            sliding_end = len(self.complexity_ranking) - n_gram\n",
    "\n",
    "        with open(filepath, 'r') as f:\n",
    "            mwes = set(f.read().split('\\n')) # make set\n",
    "            avg_mwe_complexity = 0\n",
    "            for pos in range(sliding_start, sliding_end + 1):\n",
    "                possible_mwe = ' '.join(self.tokenised_sentence[pos: pos + n_gram])\n",
    "                \n",
    "                if possible_mwe in mwes:\n",
    "                    \n",
    "                    if np.mean(self.probs[pos:pos+n_gram]) > avg_mwe_complexity:\n",
    "                        avg_mwe_complexity = np.mean(self.probs[pos:pos+n_gram])\n",
    "                        valid_mwes_idx = np.arange(pos, pos+n_gram, 1)\n",
    "                        mwe_found = possible_mwe\n",
    "                    else:\n",
    "                        continue\n",
    "                        \n",
    "        if avg_mwe_complexity > 0:\n",
    "            self.idx_to_plainify = valid_mwes_idx\n",
    "        else:\n",
    "            self.idx_to_plainify = [complex_word_pos]\n",
    "        \n",
    "    \n",
    "    def find_all_ngram_mwes(self):\n",
    "        # returns: self.idx_to_plainify the indices of the longest mwe found\n",
    "        \n",
    "        if not self.is_complex:\n",
    "            raise ValueError('Sentence is not complex')\n",
    "        \n",
    "        # give priority to longer MWEs\n",
    "        n_gram_files = {2: two_gram_mwes_list, 3: three_gram_mwes_list, 4:four_gram_mwes_list}\n",
    "        \n",
    "        for n in reversed(range(2,5)):\n",
    "            self.find_MWEs_w_most_complex_word(n, n_gram_files[n])\n",
    "            \n",
    "            if len(self.idx_to_plainify) == n: # if such mwe is found\n",
    "                break\n",
    "    \n",
    "    def one_step_plainify(self):\n",
    "        idx_start = self.idx_to_plainify[0]\n",
    "        idx_end = self.idx_to_plainify[-1]+1\n",
    "        print(f'Found complex word or expression: ### {\" \".join(self.tokenised_sentence[idx_start:idx_end])} ###. Plainifying...')\n",
    "        processed_sentence = tokeniseUntokenise(self.sentence, tokenizer)\n",
    "        forward_result = getTokenReplacement(processed_sentence, idx_start, len(self.idx_to_plainify), \n",
    "                                  tokenizer, model, similm, tokenfreq, embeddings, vocabulary2,\n",
    "                                  verbose=False, backwards=False, maxDepth=3, maxBreadth=16, alpha=(1/9,6/9,2/9))\n",
    "        backward_result = getTokenReplacement(processed_sentence, idx_start, len(self.idx_to_plainify),\n",
    "                                  tokenizer, model, similm, tokenfreq, embeddings, vocabulary2, \n",
    "                                  verbose=False, backwards=True, maxDepth=3, maxBreadth=16, alpha=(1/9,6/9,2/9))\n",
    "        words, scores = aggregateResults((forward_result, backward_result))\n",
    "        words = [w.replace('#', '') for w in words]\n",
    "        print(f'Suggested top 5 subtitutions: {words[:5]}')\n",
    "        return words[0].split(' ')\n",
    "        \n",
    "    \n",
    "    def sub_in_sentence(self, substitution):\n",
    "        # plugs a substitution in the sentence, then updates complexity scores\n",
    "        substitution_len = len(substitution)\n",
    "        \n",
    "        idx_start = self.idx_to_plainify[0]\n",
    "        idx_end = self.idx_to_plainify[-1]+1\n",
    "        \n",
    "        self.tokenised_sentence = self.tokenised_sentence[:idx_start] + substitution + self.tokenised_sentence[idx_end:]\n",
    "        self.sentence = ' '.join(self.tokenised_sentence)\n",
    "        self.bin_labels = list(self.bin_labels[:idx_start]) + [0] * substitution_len + list(self.bin_labels[idx_end:])\n",
    "        self.label_complex_words(init=False)\n",
    "        print(f'\\n\\t Sentence after substitution: {self.sentence}\\n')\n",
    "        \n",
    "    def recursive_greedy_plainify(self, max_steps=float('inf')):\n",
    "        n = 1\n",
    "        while self.is_complex and n < max_steps:\n",
    "            self.find_all_ngram_mwes()\n",
    "            sub = self.one_step_plainify()\n",
    "            self.sub_in_sentence(sub)\n",
    "            n += 1\n",
    "        print(f'Simplification complete.', end='\\r')\n",
    "    \n",
    "    def recursive_beam_search_plainfy(self, beam_width):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75316e7",
   "metadata": {},
   "source": [
    "#### Example sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "476bcdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 15:59:00.884765: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found complex word or expression: ### descriptions of ###. Plainifying...\n",
      "Suggested top 5 subtitutions: ['measures of', 'estimates of', 'determination of', 'expression of', 'values of']\n",
      "\n",
      "\t Sentence after substitution: probability is the branch of mathematics concerning numerical measures of how likely an event is to occur , or how likely it is that a proposition is true .\n",
      "\n",
      "Found complex word or expression: ### probability ###. Plainifying...\n",
      "Suggested top 5 subtitutions: ['probability theory', 'probability', '. probability', 'or probability', 'theory']\n",
      "\n",
      "\t Sentence after substitution: probability theory is the branch of mathematics concerning numerical measures of how likely an event is to occur , or how likely it is that a proposition is true .\n",
      "\n",
      "Found complex word or expression: ### a proposition ###. Plainifying...\n",
      "Suggested top 5 subtitutions: ['it', 'a statement', 'something', 'a claim', 'an event']\n",
      "\n",
      "\t Sentence after substitution: probability theory is the branch of mathematics concerning numerical measures of how likely an event is to occur , or how likely it is that it is true .\n",
      "\n",
      "Found complex word or expression: ### of mathematics ###. Plainifying...\n",
      "Suggested top 5 subtitutions: ['of mathematics', 'of probability theory', 'of', 'of probability', 'of science']\n",
      "\n",
      "\t Sentence after substitution: probability theory is the branch of mathematics concerning numerical measures of how likely an event is to occur , or how likely it is that it is true .\n",
      "\n",
      "Found complex word or expression: ### concerning ###. Plainifying...\n",
      "Suggested top 5 subtitutions: ['concerning', 'with', 'involving', 'concerned with', 'that studies']\n",
      "\n",
      "\t Sentence after substitution: probability theory is the branch of mathematics concerning numerical measures of how likely an event is to occur , or how likely it is that it is true .\n",
      "\n",
      "Found complex word or expression: ### numerical ###. Plainifying...\n",
      "Suggested top 5 subtitutions: ['the', 'various', 'numerical', 'measures or', 'probability']\n",
      "\n",
      "\t Sentence after substitution: probability theory is the branch of mathematics concerning the measures of how likely an event is to occur , or how likely it is that it is true .\n",
      "\n",
      "Found complex word or expression: ### the branch of ###. Plainifying...\n",
      "Suggested top 5 subtitutions: ['the', 'part of', 'a branch of', 'a', 'branch of']\n",
      "\t Simplificaiton complete or no complex expression found.\n",
      "\n",
      "\n",
      "\t Sentence after substitution: probability theory is the mathematics concerning the measures of how likely an event is to occur , or how likely it is that it is true .\n",
      "\n",
      "Simplification complete.\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"Probability is the branch of mathematics concerning numerical descriptions of how likely an event is to occur, or how likely it is that a proposition is true.\"\n",
    "sentence = ComplexSentence(input_sentence, label_model=Complexity_labeller_model, tokeniser=tokenizer, verbose=False)\n",
    "sentence.recursive_greedy_plainify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ca8e3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found complex word or expression: ### a sip of coffee ###. Plainifying...\n",
      "Suggested top 5 subtitutions: ['a break', 'it', 'off', 'over', 'a deep breath']\n",
      "\t Simplificaiton complete or no complex expression found.\n",
      "\n",
      "\n",
      "\t Sentence after substitution: i took a break and kept working .\n",
      "\n",
      "Simplification complete.\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"I took a sip of coffee and kept working.\"\n",
    "\n",
    "sentence = ComplexSentence(input_sentence, label_model=Complexity_labeller_model, tokeniser=tokenizer, verbose=False)\n",
    "sentence.recursive_greedy_plainify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3da3e902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found complex word or expression: ### fundamental ###. Plainifying...\n",
      "Suggested top 5 subtitutions: ['fundamental', 'new', 'basic', 'important', 'key']\n",
      "\n",
      "\t Sentence after substitution: we will first introduce several fundamental concepts .\n",
      "\n",
      "Found complex word or expression: ### introduce ###. Plainifying...\n",
      "Suggested top 5 subtitutions: ['introduce', 'establish', 'define', 'discuss', 'present']\n",
      "\n",
      "\t Sentence after substitution: we will first introduce several fundamental concepts .\n",
      "\n",
      "Found complex word or expression: ### concepts ###. Plainifying...\n",
      "Suggested top 5 subtitutions: ['concepts', 'principles', 'ideas', 'elements', 'questions']\n",
      "\t Simplificaiton complete or no complex expression found.\n",
      "\n",
      "\n",
      "\t Sentence after substitution: we will first introduce several fundamental concepts .\n",
      "\n",
      "Simplification complete.\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"We will first introduce several fundamental concepts.\"\n",
    "\n",
    "sentence = ComplexSentence(input_sentence, label_model=Complexity_labeller_model, tokeniser=tokenizer, verbose=False)\n",
    "sentence.recursive_greedy_plainify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59608142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found complex word or expression: ### patterns in ###. Plainifying...\n",
      "Suggested top 5 subtitutions: ['and process', 'and understand', 'patterns in', 'and interpret', 'or process']\n",
      "\n",
      "\t Sentence after substitution: a neural network is a series of rules that attempt to recognize and process a set of data through a process that is the way the human brain operates .\n",
      "\n",
      "Found complex word or expression: ### operates ###. Plainifying...\n",
      "Suggested top 5 subtitutions: ['works', 'operates', 'processes information', 'processes', 'functions']\n",
      "\n",
      "\t Sentence after substitution: a neural network is a series of rules that attempt to recognize and process a set of data through a process that is the way the human brain works .\n",
      "\n",
      "Found complex word or expression: ### a process that ###. Plainifying...\n",
      "Suggested top 5 subtitutions: ['this', 'it', 'that', '. this', 'which']\n",
      "\n",
      "\t Sentence after substitution: a neural network is a series of rules that attempt to recognize and process a set of data through this is the way the human brain works .\n",
      "\n",
      "Found complex word or expression: ### is a series of ###. Plainifying...\n",
      "Suggested top 5 subtitutions: ['of', 'of simple', 'composed of', 'and', 'or']\n",
      "\n",
      "\t Sentence after substitution: a neural network of rules that attempt to recognize and process a set of data through this is the way the human brain works .\n",
      "\n",
      "Found complex word or expression: ### to recognize ###. Plainifying...\n",
      "Suggested top 5 subtitutions: ['to store', 'to', 'to process', 'to recognize', 'to find']\n",
      "\n",
      "\t Sentence after substitution: a neural network of rules that attempt to store and process a set of data through this is the way the human brain works .\n",
      "\n",
      "Found complex word or expression: ### attempt to ###. Plainifying...\n",
      "Suggested top 5 subtitutions: ['can', 'attempt to', 'work to', 'are used to', 'is used to']\n",
      "\n",
      "\t Sentence after substitution: a neural network of rules that can store and process a set of data through this is the way the human brain works .\n",
      "\n",
      "Found complex word or expression: ### neural ###. Plainifying...\n",
      "Suggested top 5 subtitutions: ['neural', 'complex', 'network or', 'social', 'large']\n",
      "\n",
      "\t Sentence after substitution: a neural network of rules that can store and process a set of data through this is the way the human brain works .\n",
      "\n",
      "Found complex word or expression: ### network of ###. Plainifying...\n",
      "Suggested top 5 subtitutions: ['network of', 'system of', 'set of', 'train of', 'network']\n",
      "\n",
      "\t Sentence after substitution: a neural network of rules that can store and process a set of data through this is the way the human brain works .\n",
      "\n",
      "Found complex word or expression: ### of data ###. Plainifying...\n",
      "Suggested top 5 subtitutions: ['of data', 'of information', 'of', 'of data .', 'of information .']\n",
      "\t Simplificaiton complete or no complex expression found.\n",
      "\n",
      "\n",
      "\t Sentence after substitution: a neural network of rules that can store and process a set of data through this is the way the human brain works .\n",
      "\n",
      "Simplification complete.\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"A neural network is a series of rules that attempt to recognize patterns in a set of data through a process that is the way the human brain operates.\"\n",
    "\n",
    "sentence = ComplexSentence(input_sentence, label_model=Complexity_labeller_model, tokeniser=tokenizer, verbose=False)\n",
    "sentence.recursive_greedy_plainify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be31f532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7d3ecc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                   | 0/359 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untokenised sentence: one side of the armed conflicts is composed mainly of the sudanese military and the janjaweed , a sudanese militia group recruited mostly from the afro - arab abbala tribes of the northern rizeigat region in sudan .\n",
      "Tokenised sentence: ['one', 'side', 'of', 'the', 'armed', 'conflicts', 'is', 'composed', 'mainly', 'of', 'the', 'sudanese', 'military', 'and', 'the', 'janjaweed', ',', 'a', 'sudanese', 'militia', 'group', 'recruited', 'mostly', 'from', 'the', 'afro', '-', 'arab', 'abbala', 'tribes', 'of', 'the', 'northern', 'rizeigat', 'region', 'in', 'sudan', '.']\n",
      "Complex probs: [4.8367318e-04 4.8353723e-03 4.7576093e-05 7.4103511e-05 3.4064423e-02\n",
      " 8.7893146e-01 5.3721265e-05 8.3323532e-01 2.5257823e-01 4.1494641e-05\n",
      " 7.6524419e-05 7.9000813e-01 9.7666979e-02 6.3776330e-05 8.4813066e-05\n",
      " 0.0000000e+00 0.0000000e+00 8.4037543e-05 8.7213838e-01 7.7302271e-01\n",
      " 1.0367018e-03 9.0394229e-01 1.2732967e-02 5.6814646e-05 8.6479675e-05\n",
      " 6.3271761e-01 0.0000000e+00 5.3437324e-03 0.0000000e+00 7.1683222e-01\n",
      " 4.1801886e-05 8.0338134e-05 8.6018294e-03 0.0000000e+00 1.1892053e-01\n",
      " 3.8908358e-05 6.1245948e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0]\n",
      "\t Most complex word: recruited \n",
      "\n",
      "Found complex word or expression: ### recruited ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                           | 1/359 [00:10<59:54, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['recruited', 'formed', 'made', 'made up', 'composed']\n",
      "Complex probs: [4.8367318e-04 4.8353723e-03 4.7576093e-05 7.4103511e-05 3.4064423e-02\n",
      " 8.7893146e-01 5.3721265e-05 8.3323532e-01 2.5257823e-01 4.1494641e-05\n",
      " 7.6524419e-05 7.9000813e-01 9.7666979e-02 6.3776330e-05 8.4813066e-05\n",
      " 0.0000000e+00 0.0000000e+00 8.4037543e-05 8.7213838e-01 7.7302271e-01\n",
      " 1.0367018e-03 9.0394229e-01 1.2732967e-02 5.6814646e-05 8.6479675e-05\n",
      " 6.3271761e-01 0.0000000e+00 5.3437324e-03 0.0000000e+00 7.1683222e-01\n",
      " 4.1801886e-05 8.0338134e-05 8.6018294e-03 0.0000000e+00 1.1892053e-01\n",
      " 3.8908358e-05 6.1245948e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0]\n",
      "\t Most complex word: conflicts \n",
      "\n",
      "\n",
      "\t Sentence after substitution: one side of the armed conflicts is composed mainly of the sudanese military and the janjaweed , a sudanese militia group recruited mostly from the afro - arab abbala tribes of the northern rizeigat region in sudan .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: jeddah is the principal gateway to mecca , islam ' s holiest city , which able - bodied muslims are required to visit at least once in their lifetime .\n",
      "Tokenised sentence: ['jeddah', 'is', 'the', 'principal', 'gateway', 'to', 'mecca', ',', 'islam', \"'\", 's', 'holiest', 'city', ',', 'which', 'able', '-', 'bodied', 'muslims', 'are', 'required', 'to', 'visit', 'at', 'least', 'once', 'in', 'their', 'lifetime', '.']\n",
      "Complex probs: [0.0000000e+00 5.8313512e-05 1.0722025e-04 8.5629094e-01 7.3251051e-01\n",
      " 5.9590726e-05 4.5728719e-01 0.0000000e+00 3.8236339e-02 0.0000000e+00\n",
      " 2.4159947e-04 0.0000000e+00 2.0433872e-03 0.0000000e+00 1.3852671e-04\n",
      " 2.2718953e-03 0.0000000e+00 7.2764838e-01 4.0925667e-01 5.2970110e-05\n",
      " 1.9964947e-01 5.9380043e-05 5.8166496e-03 3.2018826e-05 1.7152673e-04\n",
      " 3.3696718e-03 4.3551619e-05 1.7303621e-04 9.0392327e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\t Most complex word: lifetime \n",
      "\n",
      "Found complex word or expression: ### lifetime ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏                                        | 2/359 [00:21<1:05:16, 10.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['lifetime', 'life', 'lives', 'lifetimes', 'entire lifetime']\n",
      "Complex probs: [0.0000000e+00 5.8313512e-05 1.0722025e-04 8.5629094e-01 7.3251051e-01\n",
      " 5.9590726e-05 4.5728719e-01 0.0000000e+00 3.8236339e-02 0.0000000e+00\n",
      " 2.4159947e-04 0.0000000e+00 2.0433872e-03 0.0000000e+00 1.3852671e-04\n",
      " 2.2718953e-03 0.0000000e+00 7.2764838e-01 4.0925667e-01 5.2970110e-05\n",
      " 1.9964947e-01 5.9380043e-05 5.8166496e-03 3.2018826e-05 1.7152673e-04\n",
      " 3.3696718e-03 4.3551619e-05 1.7303621e-04 9.0392327e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: principal \n",
      "\n",
      "\n",
      "\t Sentence after substitution: jeddah is the principal gateway to mecca , islam ' s holiest city , which able - bodied muslims are required to visit at least once in their lifetime .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: the great dark spot is thought to represent a hole in the methane cloud deck of neptune .\n",
      "Tokenised sentence: ['the', 'great', 'dark', 'spot', 'is', 'thought', 'to', 'represent', 'a', 'hole', 'in', 'the', 'methane', 'cloud', 'deck', 'of', 'neptune', '.']\n",
      "Complex probs: [1.6696723e-04 1.8307345e-03 2.0089222e-02 4.7816619e-01 5.2481584e-05\n",
      " 8.4377322e-03 5.9240680e-05 7.7582723e-01 1.4786412e-04 1.2838614e-01\n",
      " 4.6316094e-05 8.2688697e-05 7.4998939e-01 7.6932818e-02 1.0171186e-01\n",
      " 5.0125887e-05 7.1832055e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0]\n",
      "\t Most complex word: represent \n",
      "\n",
      "Found complex word or expression: ### represent a ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▎                                        | 3/359 [00:42<1:32:11, 15.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['be a', 'a', 'be', 'be a black', 'be a dark']\n",
      "Complex probs: [1.7278924e-04 2.0231667e-03 2.3080757e-02 5.0133842e-01 5.4381133e-05\n",
      " 1.0870355e-02 5.6188772e-05 3.5083503e-04 1.8481592e-04 1.3900436e-01\n",
      " 4.6779252e-05 8.0633319e-05 7.1507895e-01 6.9303282e-02 9.3189731e-02\n",
      " 4.9492548e-05 6.9926518e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0]\n",
      "\t Most complex word: methane \n",
      "\n",
      "\n",
      "\t Sentence after substitution: the great dark spot is thought to be a hole in the methane cloud deck of neptune .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: his next work , saturday , follows an especially eventful day in the life of a successful neurosurgeon .\n",
      "Tokenised sentence: ['his', 'next', 'work', ',', 'saturday', ',', 'follows', 'an', 'especially', 'eventful', 'day', 'in', 'the', 'life', 'of', 'a', 'successful', 'neurosurgeon', '.']\n",
      "Complex probs: [5.63501555e-04 1.35765166e-03 1.77612342e-03 0.00000000e+00\n",
      " 4.68642870e-03 0.00000000e+00 3.31495345e-01 1.14659706e-04\n",
      " 6.99338794e-01 0.00000000e+00 5.04433061e-04 3.29595641e-05\n",
      " 8.58873027e-05 2.86263367e-03 4.51736050e-05 1.06752595e-04\n",
      " 9.49162185e-01 0.00000000e+00 0.00000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0]\n",
      "\t Most complex word: successful \n",
      "\n",
      "Found complex word or expression: ### of a successful ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▍                                        | 4/359 [01:01<1:40:33, 17.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['of a', 'of', 'of the', 'of this', 'a']\n",
      "Complex probs: [5.6531065e-04 1.3636189e-03 1.7833402e-03 0.0000000e+00 4.7183288e-03\n",
      " 0.0000000e+00 3.3276474e-01 1.1485055e-04 6.9664073e-01 0.0000000e+00\n",
      " 5.0527998e-04 3.2677079e-05 8.5244661e-05 2.9047246e-03 4.4476466e-05\n",
      " 1.1261789e-04 0.0000000e+00 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: especially \n",
      "\n",
      "\n",
      "\t Sentence after substitution: his next work , saturday , follows an especially eventful day in the life of a neurosurgeon .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: the tarantula , the trickster character , spun a black cord and , attaching it to the ball , crawled away fast to the east , pulling on the cord with all his strength .\n",
      "Tokenised sentence: ['the', 'tarantula', ',', 'the', 'trickster', 'character', ',', 'spun', 'a', 'black', 'cord', 'and', ',', 'attaching', 'it', 'to', 'the', 'ball', ',', 'crawled', 'away', 'fast', 'to', 'the', 'east', ',', 'pulling', 'on', 'the', 'cord', 'with', 'all', 'his', 'strength', '.']\n",
      "Complex probs: [1.4647038e-04 0.0000000e+00 0.0000000e+00 7.8662008e-05 0.0000000e+00\n",
      " 8.1203640e-01 0.0000000e+00 6.2899256e-01 9.4265008e-05 1.9388259e-03\n",
      " 6.0755670e-01 7.4195159e-05 0.0000000e+00 0.0000000e+00 9.2603652e-05\n",
      " 5.0745657e-05 1.1409628e-04 7.3682332e-01 0.0000000e+00 6.7109102e-01\n",
      " 1.1207665e-03 6.8786067e-01 5.1060702e-05 1.0022406e-04 5.8155712e-03\n",
      " 0.0000000e+00 5.8346784e-01 4.7665235e-05 7.7256831e-05 7.7491862e-01\n",
      " 5.4105836e-05 2.2788355e-04 3.4095001e-04 9.0454614e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0]\n",
      "\t Most complex word: strength \n",
      "\n",
      "Found complex word or expression: ### with all his strength ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▌                                        | 5/359 [01:20<1:43:26, 17.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['as well', 'once more', 'as he went', 'once again', 'more and more']\n",
      "Complex probs: [1.46517326e-04 0.00000000e+00 0.00000000e+00 7.87552999e-05\n",
      " 0.00000000e+00 8.12622666e-01 0.00000000e+00 6.30115628e-01\n",
      " 9.43936466e-05 1.94561330e-03 6.09139204e-01 7.43408964e-05\n",
      " 0.00000000e+00 0.00000000e+00 9.28645240e-05 5.08628036e-05\n",
      " 1.14718663e-04 7.38877535e-01 0.00000000e+00 6.74028397e-01\n",
      " 1.13344053e-03 6.89331114e-01 5.10645514e-05 1.00619356e-04\n",
      " 5.83222276e-03 0.00000000e+00 5.69001079e-01 4.60263327e-05\n",
      " 7.26420622e-05 6.40622020e-01 7.57230810e-05 9.52526578e-04\n",
      " 0.00000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0]\n",
      "\t Most complex word: character \n",
      "\n",
      "\n",
      "\t Sentence after substitution: the tarantula , the trickster character , spun a black cord and , attaching it to the ball , crawled away fast to the east , pulling on the cord as well .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: there he died six weeks later , on 13 january 888 .\n",
      "Tokenised sentence: ['there', 'he', 'died', 'six', 'weeks', 'later', ',', 'on', '13', 'january', '888', '.']\n",
      "Complex probs: [5.2769564e-04 1.5221130e-04 5.0036097e-03 1.1432002e-03 6.6026943e-03\n",
      " 1.4037095e-03 0.0000000e+00 4.5404930e-05 1.6130999e-04 4.4124941e-03\n",
      " 0.0000000e+00 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\t Simplificaiton complete or no complex expression found.\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: they are culturally akin to the coastal peoples of papua new guinea .\n",
      "Tokenised sentence: ['they', 'are', 'culturally', 'akin', 'to', 'the', 'coastal', 'peoples', 'of', 'papua', 'new', 'guinea', '.']\n",
      "Complex probs: [2.3255708e-04 6.6406836e-05 9.1595727e-01 7.2231364e-01 5.7739908e-05\n",
      " 1.0259508e-04 7.9565650e-01 7.1054769e-01 4.5962821e-05 5.7728374e-01\n",
      " 5.2403763e-04 5.7118720e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 1 1 0 0 1 1 0 1 0 1 0]\n",
      "\t Most complex word: culturally \n",
      "\n",
      "Found complex word or expression: ### culturally ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▊                                        | 7/359 [01:31<1:07:37, 11.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['culturally', 'most', 'most closely', 'ethnically', 'linguistically']\n",
      "Complex probs: [2.3255708e-04 6.6406836e-05 9.1595727e-01 7.2231364e-01 5.7739908e-05\n",
      " 1.0259508e-04 7.9565650e-01 7.1054769e-01 4.5962821e-05 5.7728374e-01\n",
      " 5.2403763e-04 5.7118720e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 1 0 0 1 1 0 1 0 1 0]\n",
      "\t Most complex word: coastal \n",
      "\n",
      "\n",
      "\t Sentence after substitution: they are culturally akin to the coastal peoples of papua new guinea .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: since 2000 , the recipient of the kate greenaway medal has also been presented with the colin mears award to the value of £ 5000 .\n",
      "Tokenised sentence: ['since', '2000', ',', 'the', 'recipient', 'of', 'the', 'kate', 'greenaway', 'medal', 'has', 'also', 'been', 'presented', 'with', 'the', 'colin', 'mears', 'award', 'to', 'the', 'value', 'of', '£', '5000', '.']\n",
      "Complex probs: [2.7441280e-04 1.8918097e-03 0.0000000e+00 1.1253642e-04 9.2846304e-01\n",
      " 6.1621453e-05 9.5000738e-05 7.0560968e-01 0.0000000e+00 9.9230893e-02\n",
      " 1.2296185e-04 4.5109709e-04 5.3224864e-04 4.5791799e-01 5.4981949e-05\n",
      " 1.1253620e-04 1.1136379e-01 0.0000000e+00 3.9885480e-02 5.1288600e-05\n",
      " 1.0744778e-04 2.9958397e-01 5.7868616e-05 0.0000000e+00 1.6498052e-03\n",
      " 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: recipient \n",
      "\n",
      "Found complex word or expression: ### the recipient of the ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▉                                        | 8/359 [01:47<1:13:52, 12.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['the', 'and the', 'a', 'when the', 'where the']\n",
      "Complex probs: [2.8168818e-04 1.8665724e-03 0.0000000e+00 1.0457249e-04 7.3089993e-01\n",
      " 0.0000000e+00 1.1015900e-01 1.2568579e-04 4.5075174e-04 5.3039577e-04\n",
      " 4.5946726e-01 5.5302025e-05 1.1327909e-04 1.1469454e-01 0.0000000e+00\n",
      " 4.0851656e-02 5.1492865e-05 1.0813470e-04 3.0339763e-01 5.8051955e-05\n",
      " 0.0000000e+00 1.6631703e-03 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: kate \n",
      "\n",
      "\n",
      "\t Sentence after substitution: since 2000 , the kate greenaway medal has also been presented with the colin mears award to the value of £ 5000 .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: following the drummers are dancers , who often play the sogo  (  a tiny drum that makes almost no sound  )  and tend to have more elaborate — even acrobatic — choreography .\n",
      "Tokenised sentence: ['following', 'the', 'drummers', 'are', 'dancers', ',', 'who', 'often', 'play', 'the', 'sogo', '(', 'a', 'tiny', 'drum', 'that', 'makes', 'almost', 'no', 'sound', ')', 'and', 'tend', 'to', 'have', 'more', 'elaborate', '—', 'even', 'acrobatic', '—', 'choreography', '.']\n",
      "Complex probs: [3.06678325e-01 1.21461824e-04 0.00000000e+00 8.95327103e-05\n",
      " 8.16609323e-01 0.00000000e+00 1.41991695e-04 1.41331495e-03\n",
      " 4.40552831e-03 9.49837995e-05 0.00000000e+00 0.00000000e+00\n",
      " 1.03265265e-04 7.63785243e-01 6.72377944e-01 7.07261570e-05\n",
      " 7.79808091e-04 4.92916675e-03 2.44316208e-04 3.74937453e-03\n",
      " 0.00000000e+00 6.74135445e-05 6.10611439e-01 5.08620760e-05\n",
      " 1.14370756e-04 1.75949142e-04 8.21122885e-01 0.00000000e+00\n",
      " 3.25928908e-04 0.00000000e+00 0.00000000e+00 8.59414101e-01\n",
      " 0.00000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0]\n",
      "\t Most complex word: choreography \n",
      "\n",
      "Found complex word or expression: ### choreography ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█                                        | 9/359 [01:55<1:07:09, 11.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['dances', 'dance moves', 'moves', 'dance', 'dance steps']\n",
      "Complex probs: [3.06933552e-01 1.21495657e-04 0.00000000e+00 8.95787380e-05\n",
      " 8.16899896e-01 0.00000000e+00 1.42124030e-04 1.41405419e-03\n",
      " 4.41132532e-03 9.51210313e-05 0.00000000e+00 0.00000000e+00\n",
      " 1.03380335e-04 7.64848471e-01 6.73987448e-01 7.08666412e-05\n",
      " 7.83032738e-04 4.96569555e-03 2.45611533e-04 3.78561928e-03\n",
      " 0.00000000e+00 6.76713171e-05 6.15869761e-01 5.11431572e-05\n",
      " 1.15711489e-04 1.79121198e-04 8.26959193e-01 0.00000000e+00\n",
      " 3.37147852e-04 0.00000000e+00 0.00000000e+00 5.36289990e-01\n",
      " 0.00000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0]\n",
      "\t Most complex word: elaborate \n",
      "\n",
      "\n",
      "\t Sentence after substitution: following the drummers are dancers , who often play the sogo ( a tiny drum that makes almost no sound ) and tend to have more elaborate — even acrobatic — dances .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: the spacecraft consists of two main elements : the nasa cassini orbiter , named after the italian - french astronomer giovanni domenico cassini , and the esa huygens probe , named after the dutch astronomer , mathematician and physicist christiaan huygens .\n",
      "Tokenised sentence: ['the', 'spacecraft', 'consists', 'of', 'two', 'main', 'elements', ':', 'the', 'nasa', 'cassini', 'orbiter', ',', 'named', 'after', 'the', 'italian', '-', 'french', 'astronomer', 'giovanni', 'domenico', 'cassini', ',', 'and', 'the', 'esa', 'huygens', 'probe', ',', 'named', 'after', 'the', 'dutch', 'astronomer', ',', 'mathematician', 'and', 'physicist', 'christiaan', 'huygens', '.']\n",
      "Complex probs: [1.88734266e-04 9.71117795e-01 8.61470520e-01 6.44011088e-05\n",
      " 1.40407807e-04 4.89361631e-03 8.34637880e-01 0.00000000e+00\n",
      " 1.01880854e-04 7.38937914e-01 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 4.40113200e-03 8.72581950e-05 8.21739231e-05\n",
      " 6.32040482e-03 0.00000000e+00 8.11827311e-04 8.25160325e-01\n",
      " 5.82220554e-01 7.31635571e-01 0.00000000e+00 0.00000000e+00\n",
      " 5.83047222e-05 8.85686532e-05 6.88260019e-01 0.00000000e+00\n",
      " 9.35294747e-01 0.00000000e+00 3.32770892e-03 7.70954430e-05\n",
      " 7.10624954e-05 1.44935966e-01 8.77263784e-01 0.00000000e+00\n",
      " 9.35431778e-01 6.82335231e-05 8.22399497e-01 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00]\n",
      "Binary complexity labels: [0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0]\n",
      "\t Most complex word: spacecraft \n",
      "\n",
      "Found complex word or expression: ### the spacecraft ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█                                       | 10/359 [02:14<1:18:39, 13.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['. it', 'the system', 'system', 'and', 'it']\n",
      "Complex probs: [0.0000000e+00 8.7323948e-05 7.7048135e-01 5.8457379e-05 1.2697546e-04\n",
      " 3.8988930e-03 8.0908138e-01 0.0000000e+00 9.9384270e-05 7.2749174e-01\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.4735060e-03 8.7591827e-05\n",
      " 8.2472616e-05 6.3960617e-03 0.0000000e+00 8.1312092e-04 8.2589555e-01\n",
      " 5.8277869e-01 7.3177898e-01 0.0000000e+00 0.0000000e+00 5.8305886e-05\n",
      " 8.8616209e-05 6.8833715e-01 0.0000000e+00 9.3525451e-01 0.0000000e+00\n",
      " 3.3274526e-03 7.7074190e-05 7.1068185e-05 1.4493273e-01 8.7722474e-01\n",
      " 0.0000000e+00 9.3542397e-01 6.8227928e-05 8.2235754e-01 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0]\n",
      "\t Most complex word: mathematician \n",
      "\n",
      "\n",
      "\t Sentence after substitution: . it consists of two main elements : the nasa cassini orbiter , named after the italian - french astronomer giovanni domenico cassini , and the esa huygens probe , named after the dutch astronomer , mathematician and physicist christiaan huygens .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: alessandro  (  \" sandro \"  )  mazzola  (  born 8 november 1942  )  is an italian former football player .\n",
      "Tokenised sentence: ['alessandro', '(', '\"', 'sandro', '\"', ')', 'mazzola', '(', 'born', '8', 'november', '1942', ')', 'is', 'an', 'italian', 'former', 'football', 'player', '.']\n",
      "Complex probs: [8.7230116e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 9.3392739e-03 6.0779996e-05\n",
      " 6.2385370e-04 4.0258327e-04 0.0000000e+00 5.3174324e-05 1.8806728e-04\n",
      " 1.5232198e-02 7.6489627e-02 3.8040016e-02 2.1380303e-02 0.0000000e+00]\n",
      "Binary complexity labels: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: alessandro \n",
      "\n",
      "Found complex word or expression: ### alessandro ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█▏                                      | 11/359 [02:31<1:23:23, 14.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['antonio', 'o', 'ro', 'alessandro', 'sandro']\n",
      "Complex probs: [8.4689081e-02 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 9.3270615e-03 6.0778722e-05\n",
      " 6.4527034e-04 4.0875113e-04 0.0000000e+00 5.3064556e-05 1.8939914e-04\n",
      " 1.5344983e-02 7.6410331e-02 3.7863191e-02 2.1254105e-02 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\t Simplificaiton complete or no complex expression found.\n",
      "\n",
      "\n",
      "\t Sentence after substitution: antonio ( \" sandro \" ) mazzola ( born 8 november 1942 ) is an italian former football player .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: it was originally thought that the debris thrown up by the collision filled in the smaller craters .\n",
      "Tokenised sentence: ['it', 'was', 'originally', 'thought', 'that', 'the', 'debris', 'thrown', 'up', 'by', 'the', 'collision', 'filled', 'in', 'the', 'smaller', 'craters', '.']\n",
      "Complex probs: [1.5150094e-04 1.0398680e-04 9.1516834e-01 9.5618833e-03 7.8062854e-05\n",
      " 1.3845632e-04 9.3120885e-01 8.3097774e-01 1.6276061e-04 8.3039391e-05\n",
      " 1.1782142e-04 8.8176328e-01 6.3125968e-01 3.7905440e-05 7.4815260e-05\n",
      " 2.8579028e-02 9.0686548e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1 0]\n",
      "\t Most complex word: debris \n",
      "\n",
      "Found complex word or expression: ### the debris ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█▎                                      | 12/359 [02:46<1:24:41, 14.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['debris', 'material', 'the dust', 'the material', 'the debris']\n",
      "Complex probs: [1.4715297e-04 1.0283700e-04 9.0757138e-01 7.5734416e-03 9.5803211e-05\n",
      " 9.5682573e-01 8.0949837e-01 1.5199084e-04 8.0117716e-05 1.1095577e-04\n",
      " 8.6435163e-01 6.0380244e-01 3.7689533e-05 7.3289360e-05 2.6736889e-02\n",
      " 9.0187848e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0]\n",
      "\t Most complex word: originally \n",
      "\n",
      "\n",
      "\t Sentence after substitution: it was originally thought that debris thrown up by the collision filled in the smaller craters .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: graham attended wheaton college from 1939 to 1943 , when he graduated with a ba in anthropology .\n",
      "Tokenised sentence: ['graham', 'attended', 'wheaton', 'college', 'from', '1939', 'to', '1943', ',', 'when', 'he', 'graduated', 'with', 'a', 'ba', 'in', 'anthropology', '.']\n",
      "Complex probs: [1.5397359e-01 8.5893947e-01 0.0000000e+00 5.0202537e-02 6.2792416e-05\n",
      " 1.2234540e-03 4.9983933e-05 2.4210715e-03 0.0000000e+00 1.1167534e-04\n",
      " 1.5439960e-04 9.7276533e-01 5.3597534e-05 1.1995402e-04 6.9074309e-01\n",
      " 5.2607858e-05 9.5760804e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0]\n",
      "\t Most complex word: graduated \n",
      "\n",
      "Found complex word or expression: ### graduated ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▍                                      | 13/359 [02:58<1:19:23, 13.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['graduated', 'was graduated', 'also graduated', 'would graduate', 'finished']\n",
      "Complex probs: [1.5397359e-01 8.5893947e-01 0.0000000e+00 5.0202537e-02 6.2792416e-05\n",
      " 1.2234540e-03 4.9983933e-05 2.4210715e-03 0.0000000e+00 1.1167534e-04\n",
      " 1.5439960e-04 9.7276533e-01 5.3597534e-05 1.1995402e-04 6.9074309e-01\n",
      " 5.2607858e-05 9.5760804e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "\t Most complex word: anthropology \n",
      "\n",
      "\n",
      "\t Sentence after substitution: graham attended wheaton college from 1939 to 1943 , when he graduated with a ba in anthropology .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: however , the bzö differs a bit in comparison to the freedom party , as is in favor of a referendum about the lisbon treaty but against an eu - withdrawal .\n",
      "Tokenised sentence: ['however', ',', 'the', 'bzo', 'differs', 'a', 'bit', 'in', 'comparison', 'to', 'the', 'freedom', 'party', ',', 'as', 'is', 'in', 'favor', 'of', 'a', 'referendum', 'about', 'the', 'lisbon', 'treaty', 'but', 'against', 'an', 'eu', '-', 'withdrawal', '.']\n",
      "Complex probs: [1.2562878e-02 0.0000000e+00 7.5826989e-05 0.0000000e+00 7.9748249e-01\n",
      " 9.6846859e-05 1.7116616e-02 4.4681288e-05 8.6847150e-01 5.5875913e-05\n",
      " 7.7068311e-05 1.1282746e-01 1.0004877e-02 0.0000000e+00 6.6138120e-05\n",
      " 6.0193041e-05 4.7725727e-05 7.6564389e-01 4.5995177e-05 1.0059096e-04\n",
      " 9.2693347e-01 9.6785174e-05 7.9683654e-05 6.9288445e-01 8.3092791e-01\n",
      " 1.4302414e-04 2.0513928e-04 1.0476153e-04 1.7880908e-01 0.0000000e+00\n",
      " 9.3654704e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 0]\n",
      "\t Most complex word: withdrawal \n",
      "\n",
      "Found complex word or expression: ### withdrawal ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▌                                      | 14/359 [03:20<1:33:54, 16.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['led government', 'one', 'vote', 'referendum', 'no']\n",
      "Complex probs: [1.25767970e-02 0.00000000e+00 7.58391398e-05 0.00000000e+00\n",
      " 8.01556647e-01 9.71884074e-05 1.71296969e-02 4.46410850e-05\n",
      " 8.67424309e-01 5.57636558e-05 7.68755708e-05 1.12008646e-01\n",
      " 9.94618051e-03 0.00000000e+00 6.60319347e-05 6.00915337e-05\n",
      " 4.76323803e-05 7.64481306e-01 4.59378898e-05 1.00335747e-04\n",
      " 9.26631331e-01 9.66239750e-05 7.94492662e-05 6.91547453e-01\n",
      " 8.30517769e-01 1.43086610e-04 2.06144920e-04 1.04936400e-04\n",
      " 1.79461628e-01 0.00000000e+00 8.23820382e-02 1.72467247e-01\n",
      " 0.00000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: referendum \n",
      "\n",
      "\n",
      "\t Sentence after substitution: however , the bzo differs a bit in comparison to the freedom party , as is in favor of a referendum about the lisbon treaty but against an eu - led government .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: many species had vanished by the end of the nineteenth century , with european settlement .\n",
      "Tokenised sentence: ['many', 'species', 'had', 'vanished', 'by', 'the', 'end', 'of', 'the', 'nineteenth', 'century', ',', 'with', 'european', 'settlement', '.']\n",
      "Complex probs: [6.4078183e-04 9.5736498e-01 5.1276817e-04 9.5745546e-01 1.4481695e-04\n",
      " 1.5327947e-04 1.3234979e-02 5.0079165e-05 9.7945544e-05 7.9469573e-01\n",
      " 4.5964631e-01 0.0000000e+00 3.8055063e-05 2.3687597e-02 8.5736531e-01\n",
      " 0.0000000e+00]\n",
      "Binary complexity labels: [0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "\t Most complex word: vanished \n",
      "\n",
      "Found complex word or expression: ### had vanished ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▋                                      | 15/359 [03:39<1:38:46, 17.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['had disappeared', 'had completely disappeared', 'had appeared', 'disappeared', 'appeared']\n",
      "Complex probs: [6.0569204e-04 9.5503968e-01 4.8365403e-04 9.8228514e-01 1.5404492e-04\n",
      " 1.4797048e-04 1.2979529e-02 4.9835147e-05 9.7710923e-05 7.9417634e-01\n",
      " 4.5746562e-01 0.0000000e+00 3.8000704e-05 2.3585599e-02 8.5698122e-01\n",
      " 0.0000000e+00]\n",
      "Binary complexity labels: [0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "\t Most complex word: species \n",
      "\n",
      "\n",
      "\t Sentence after substitution: many species had disappeared by the end of the nineteenth century , with european settlement .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: in 1987 wexler was inducted into the rock and roll hall of fame .\n",
      "Tokenised sentence: ['in', '1987', 'wexler', 'was', 'inducted', 'into', 'the', 'rock', 'and', 'roll', 'hall', 'of', 'fame', '.']\n",
      "Complex probs: [5.27353914e-05 7.58231734e-04 0.00000000e+00 1.16496674e-04\n",
      " 9.36812639e-01 1.70900967e-04 1.14342642e-04 2.68149942e-01\n",
      " 9.58344681e-05 2.88676888e-01 2.41268620e-01 5.15334468e-05\n",
      " 7.84421623e-01 0.00000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "\t Most complex word: inducted \n",
      "\n",
      "Found complex word or expression: ### was inducted into the ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▊                                      | 16/359 [03:59<1:42:46, 17.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['entered the', 'joined the', 'entered into the', 'elected to the', 'entered']\n",
      "Complex probs: [5.1117797e-05 6.2807911e-04 0.0000000e+00 9.2672127e-01 1.2447259e-04\n",
      " 2.4064952e-01 1.0047802e-04 3.4499979e-01 2.8435692e-01 5.4039578e-05\n",
      " 8.0575961e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\t Most complex word: fame \n",
      "\n",
      "\n",
      "\t Sentence after substitution: in 1987 wexler entered the rock and roll hall of fame .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: in its pure form , dextromethorphan occurs as a white powder .\n",
      "Tokenised sentence: ['in', 'its', 'pure', 'form', ',', 'dextromethorphan', 'occurs', 'as', 'a', 'white', 'powder', '.']\n",
      "Complex probs: [5.8771962e-05 1.8440526e-04 7.2020632e-01 6.4851199e-03 0.0000000e+00\n",
      " 0.0000000e+00 7.8117692e-01 5.4724744e-05 1.1244696e-04 1.0596204e-03\n",
      " 5.0036186e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 1 0 0 0 1 0 0 0 1 0]\n",
      "\t Most complex word: occurs \n",
      "\n",
      "Found complex word or expression: ### occurs ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|█▉                                      | 17/359 [04:11<1:32:56, 16.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['occurs', 'exists', 'appears', 'occurs naturally', 'comes']\n",
      "Complex probs: [5.8771962e-05 1.8440526e-04 7.2020632e-01 6.4851199e-03 0.0000000e+00\n",
      " 0.0000000e+00 7.8117692e-01 5.4724744e-05 1.1244696e-04 1.0596204e-03\n",
      " 5.0036186e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "\t Most complex word: pure \n",
      "\n",
      "\n",
      "\t Sentence after substitution: in its pure form , dextromethorphan occurs as a white powder .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: admission to tsinghua is extremely competitive .\n",
      "Tokenised sentence: ['admission', 'to', 'tsinghua', 'is', 'extremely', 'competitive', '.']\n",
      "Complex probs: [8.2911277e-01 7.8101955e-05 0.0000000e+00 5.7975110e-05 8.0186462e-01\n",
      " 8.8886589e-01 0.0000000e+00]\n",
      "Binary complexity labels: [1 0 0 0 1 1 0]\n",
      "\t Most complex word: competitive \n",
      "\n",
      "Found complex word or expression: ### competitive ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|██                                      | 18/359 [04:18<1:15:37, 13.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['competitive', 'difficult', 'expensive', 'limited', 'high']\n",
      "Complex probs: [8.2911277e-01 7.8101955e-05 0.0000000e+00 5.7975110e-05 8.0186462e-01\n",
      " 8.8886589e-01 0.0000000e+00]\n",
      "Binary complexity labels: [1 0 0 0 1 0 0]\n",
      "\t Most complex word: admission \n",
      "\n",
      "\n",
      "\t Sentence after substitution: admission to tsinghua is extremely competitive .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: today nrc is organised as an independent , private foundation .\n",
      "Tokenised sentence: ['today', 'nrc', 'is', 'organised', 'as', 'an', 'independent', ',', 'private', 'foundation', '.']\n",
      "Complex probs: [9.3426008e-04 0.0000000e+00 5.3683067e-05 9.2266703e-01 7.6486984e-05\n",
      " 1.1256110e-04 9.0050542e-01 0.0000000e+00 4.2135663e-02 7.6762956e-01\n",
      " 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 1 0 0 1 0 0 1 0]\n",
      "\t Most complex word: organised \n",
      "\n",
      "Found complex word or expression: ### organised ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|██▏                                       | 19/359 [04:21<58:36, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['organized', 'run', 'established', 'registered', 'managed']\n",
      "Complex probs: [9.2023949e-04 0.0000000e+00 5.2215011e-05 8.9662355e-01 8.0293859e-05\n",
      " 1.1706125e-04 9.0560997e-01 0.0000000e+00 4.4150714e-02 7.7215999e-01\n",
      " 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 1 0 0 1 0]\n",
      "\t Most complex word: independent \n",
      "\n",
      "\n",
      "\t Sentence after substitution: today nrc is organized as an independent , private foundation .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: it is situated at the coast of the baltic sea , where it encloses the city of stralsund .\n",
      "Tokenised sentence: ['it', 'is', 'situated', 'at', 'the', 'coast', 'of', 'the', 'baltic', 'sea', ',', 'where', 'it', 'encloses', 'the', 'city', 'of', 'stralsund', '.']\n",
      "Complex probs: [1.7257451e-04 5.5814518e-05 9.4125313e-01 4.7788442e-05 9.2311209e-05\n",
      " 1.8614635e-02 4.4441022e-05 8.3417086e-05 6.4331514e-01 1.1903289e-03\n",
      " 0.0000000e+00 7.9863326e-05 7.6760698e-05 0.0000000e+00 1.2777673e-04\n",
      " 9.9516204e-03 5.1845462e-05 0.0000000e+00 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: situated \n",
      "\n",
      "Found complex word or expression: ### is situated ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██▏                                     | 20/359 [04:36<1:06:45, 11.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['is located', 'is', 'is situated', 'ends', 'lies']\n",
      "Complex probs: [1.8214261e-04 5.4329295e-05 4.4943768e-01 4.5598063e-05 9.4484232e-05\n",
      " 1.8543024e-02 4.5484448e-05 8.4525549e-05 6.5711564e-01 1.2500874e-03\n",
      " 0.0000000e+00 8.1650185e-05 7.8445672e-05 0.0000000e+00 1.2932440e-04\n",
      " 1.0356987e-02 5.2229152e-05 0.0000000e+00 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: baltic \n",
      "\n",
      "\n",
      "\t Sentence after substitution: it is located at the coast of the baltic sea , where it encloses the city of stralsund .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: he was also named 1982 \" sportsman of the year \" by sports illustrated .\n",
      "Tokenised sentence: ['he', 'was', 'also', 'named', '1982', '\"', 'sportsman', 'of', 'the', 'year', '\"', 'by', 'sports', 'illustrated', '.']\n",
      "Complex probs: [2.5512194e-04 1.2048500e-04 5.1155919e-04 7.3751821e-03 1.5118682e-03\n",
      " 0.0000000e+00 8.0551344e-01 4.4441953e-05 9.5526346e-05 9.1635040e-04\n",
      " 0.0000000e+00 9.3857620e-05 2.3135418e-01 8.7872529e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "\t Most complex word: illustrated \n",
      "\n",
      "Found complex word or expression: ### illustrated ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██▎                                     | 21/359 [04:48<1:05:52, 11.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['illustrated', 'illustrated magazine', 'illustrated .', 'illustrated international', 'illustrated sports']\n",
      "Complex probs: [2.5512194e-04 1.2048500e-04 5.1155919e-04 7.3751821e-03 1.5118682e-03\n",
      " 0.0000000e+00 8.0551344e-01 4.4441953e-05 9.5526346e-05 9.1635040e-04\n",
      " 0.0000000e+00 9.3857620e-05 2.3135418e-01 8.7872529e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: sportsman \n",
      "\n",
      "\n",
      "\t Sentence after substitution: he was also named 1982 \" sportsman of the year \" by sports illustrated .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: fives is a british sport believed to derive from the same origins as many racquet sports .\n",
      "Tokenised sentence: ['fives', 'is', 'a', 'british', 'sport', 'believed', 'to', 'derive', 'from', 'the', 'same', 'origins', 'as', 'many', 'racquet', 'sports', '.']\n",
      "Complex probs: [0.0000000e+00 6.2035346e-05 1.3427409e-04 8.5792542e-03 1.1880777e-01\n",
      " 3.4349021e-01 6.3942207e-05 8.9160132e-01 7.8604950e-05 9.7371623e-05\n",
      " 2.4858050e-03 8.1108552e-01 7.7301564e-05 2.4986302e-04 0.0000000e+00\n",
      " 1.7115714e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
      "\t Most complex word: derive \n",
      "\n",
      "Found complex word or expression: ### derive from ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██▍                                     | 22/359 [05:03<1:11:29, 12.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['have', 'be from', 'be of', 'have come from', 'have had']\n",
      "Complex probs: [0.0000000e+00 6.1004375e-05 1.3334471e-04 9.3034841e-03 1.2969419e-01\n",
      " 3.6955798e-01 5.3753960e-05 1.8879151e-04 1.4058089e-04 4.3478380e-03\n",
      " 8.4550130e-01 8.3040497e-05 2.5959351e-04 0.0000000e+00 1.6691709e-01\n",
      " 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\t Most complex word: origins \n",
      "\n",
      "\n",
      "\t Sentence after substitution: fives is a british sport believed to have the same origins as many racquet sports .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: for example , king bhumibol was born on monday , so on his birthday throughout thailand will be decorated with yellow color .\n",
      "Tokenised sentence: ['for', 'example', ',', 'king', 'bhumibol', 'was', 'born', 'on', 'monday', ',', 'so', 'on', 'his', 'birthday', 'throughout', 'thailand', 'will', 'be', 'decorated', 'with', 'yellow', 'color', '.']\n",
      "Complex probs: [5.7782865e-05 1.8406691e-02 0.0000000e+00 4.2097275e-03 0.0000000e+00\n",
      " 8.2955339e-05 3.2967284e-02 4.1695908e-05 5.8848835e-03 0.0000000e+00\n",
      " 1.6078557e-04 5.8782047e-05 3.1450784e-04 8.2889929e-02 8.8722324e-01\n",
      " 1.2326414e-02 7.7357676e-05 2.9906837e-04 9.1207451e-01 5.4135980e-05\n",
      " 7.3233992e-03 2.2524299e-02 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0]\n",
      "\t Most complex word: decorated \n",
      "\n",
      "Found complex word or expression: ### decorated with ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██▌                                     | 23/359 [05:20<1:17:39, 13.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['in', 'the', 'in the', 'covered with', 'a']\n",
      "Complex probs: [5.7795649e-05 1.8502114e-02 0.0000000e+00 4.2023775e-03 0.0000000e+00\n",
      " 8.2655286e-05 3.2898858e-02 4.1437379e-05 5.9107607e-03 0.0000000e+00\n",
      " 1.5933371e-04 5.7709411e-05 3.1266737e-04 8.3918907e-02 8.7276465e-01\n",
      " 1.2484296e-02 7.5872405e-05 5.5626011e-04 4.7393150e-05 8.4797172e-03\n",
      " 3.0403318e-02 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\t Most complex word: throughout \n",
      "\n",
      "\n",
      "\t Sentence after substitution: for example , king bhumibol was born on monday , so on his birthday throughout thailand will be in yellow color .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: both names became defunct in 2007 when they were merged into the national museum of scotland .\n",
      "Tokenised sentence: ['both', 'names', 'became', 'defunct', 'in', '2007', 'when', 'they', 'were', 'merged', 'into', 'the', 'national', 'museum', 'of', 'scotland', '.']\n",
      "Complex probs: [1.0326944e-03 2.1483062e-02 1.0595002e-03 8.6282599e-01 4.5498418e-05\n",
      " 1.7902087e-03 1.0799312e-04 2.1793305e-04 1.3451926e-04 9.0409917e-01\n",
      " 1.7978219e-04 1.1298070e-04 8.9070641e-02 8.4690982e-01 5.1123454e-05\n",
      " 6.8951344e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0]\n",
      "\t Most complex word: merged \n",
      "\n",
      "Found complex word or expression: ### merged ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██▊                                       | 24/359 [05:23<59:36, 10.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['merged', 'incorporated', 'combined', 'absorbed', 'consolidated']\n",
      "Complex probs: [1.0326944e-03 2.1483062e-02 1.0595002e-03 8.6282599e-01 4.5498418e-05\n",
      " 1.7902087e-03 1.0799312e-04 2.1793305e-04 1.3451926e-04 9.0409917e-01\n",
      " 1.7978219e-04 1.1298070e-04 8.9070641e-02 8.4690982e-01 5.1123454e-05\n",
      " 6.8951344e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "\t Most complex word: defunct \n",
      "\n",
      "\n",
      "\t Sentence after substitution: both names became defunct in 2007 when they were merged into the national museum of scotland .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: nevertheless , tagore emulated numerous styles , including craftwork from northern new ireland , haida carvings from the west coast of canada  (  british columbia  )  , and woodcuts by max pechstein .\n",
      "Tokenised sentence: ['nevertheless', ',', 'tagore', 'emulated', 'numerous', 'styles', ',', 'including', 'craftwork', 'from', 'northern', 'new', 'ireland', ',', 'haida', 'carvings', 'from', 'the', 'west', 'coast', 'of', 'canada', '(', 'british', 'columbia', ')', ',', 'and', 'woodcuts', 'by', 'max', 'pechstein', '.']\n",
      "Complex probs: [8.90322030e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 8.09883356e-01 3.88099998e-01 0.00000000e+00 1.36514857e-01\n",
      " 0.00000000e+00 6.92370813e-05 9.29043163e-03 4.79017966e-04\n",
      " 2.11136080e-02 0.00000000e+00 0.00000000e+00 8.46425533e-01\n",
      " 7.26423386e-05 1.16493786e-04 2.99407123e-03 8.48197006e-03\n",
      " 4.21966433e-05 1.29155479e-02 0.00000000e+00 1.90199784e-03\n",
      " 7.30074584e-01 0.00000000e+00 0.00000000e+00 7.16456198e-05\n",
      " 0.00000000e+00 9.58532837e-05 3.03036459e-02 0.00000000e+00\n",
      " 0.00000000e+00]\n",
      "Binary complexity labels: [1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: nevertheless \n",
      "\n",
      "Found complex word or expression: ### nevertheless ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██▊                                     | 25/359 [05:42<1:14:00, 13.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['however', '. .', 'while there', 'years', 'time']\n",
      "Complex probs: [1.32843219e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 8.03038061e-01 3.73089075e-01 0.00000000e+00 1.34795129e-01\n",
      " 0.00000000e+00 6.84087790e-05 9.16538294e-03 4.74235712e-04\n",
      " 2.09380481e-02 0.00000000e+00 0.00000000e+00 8.46102655e-01\n",
      " 7.25212158e-05 1.16410054e-04 2.98730936e-03 8.46158992e-03\n",
      " 4.21662298e-05 1.29133854e-02 0.00000000e+00 1.89924089e-03\n",
      " 7.29973793e-01 0.00000000e+00 0.00000000e+00 7.16402938e-05\n",
      " 0.00000000e+00 9.58578603e-05 3.02841216e-02 0.00000000e+00\n",
      " 0.00000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: carvings \n",
      "\n",
      "\n",
      "\t Sentence after substitution: however , tagore emulated numerous styles , including craftwork from northern new ireland , haida carvings from the west coast of canada ( british columbia ) , and woodcuts by max pechstein .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: on october 14 , 1960 , presidential candidate john f . kennedy proposed the concept of what became the peace corps on the steps of michigan union .\n",
      "Tokenised sentence: ['on', 'october', '14', ',', '1960', ',', 'presidential', 'candidate', 'john', 'f', '.', 'kennedy', 'proposed', 'the', 'concept', 'of', 'what', 'became', 'the', 'peace', 'corps', 'on', 'the', 'steps', 'of', 'michigan', 'union', '.']\n",
      "Complex probs: [5.6550762e-05 2.2518642e-03 1.3561541e-04 0.0000000e+00 8.6490565e-04\n",
      " 0.0000000e+00 5.3545952e-01 6.3686234e-01 8.9871010e-04 1.0043044e-03\n",
      " 0.0000000e+00 4.3014009e-02 8.9936382e-01 1.1050565e-04 8.9787632e-01\n",
      " 5.7330817e-05 1.3066448e-04 1.5192819e-03 1.0138755e-04 9.1062170e-03\n",
      " 7.3458773e-01 4.9900391e-05 8.7709261e-05 1.1700329e-01 4.8196314e-05\n",
      " 6.0077047e-01 9.9357851e-02 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\t Most complex word: proposed \n",
      "\n",
      "Found complex word or expression: ### proposed ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██▉                                     | 26/359 [05:49<1:03:28, 11.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['introduced', 'proposed', 'announced', 'presented', 'first proposed']\n",
      "Complex probs: [5.67286188e-05 2.27127015e-03 1.36483039e-04 0.00000000e+00\n",
      " 8.76812148e-04 0.00000000e+00 5.42548060e-01 6.44393146e-01\n",
      " 9.10239469e-04 1.03105803e-03 0.00000000e+00 4.73908372e-02\n",
      " 9.54760432e-01 1.23338337e-04 9.06708896e-01 5.81247368e-05\n",
      " 1.34302652e-04 1.59113959e-03 1.02340244e-04 9.33097489e-03\n",
      " 7.37310588e-01 4.98407535e-05 8.78216597e-05 1.18165500e-01\n",
      " 4.82118558e-05 6.03001833e-01 9.94992480e-02 0.00000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\t Most complex word: concept \n",
      "\n",
      "\n",
      "\t Sentence after substitution: on october 14 , 1960 , presidential candidate john f . kennedy introduced the concept of what became the peace corps on the steps of michigan union .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: she performed for president reagan in 1988 ' s great performances at the white house series , which aired on the public broadcasting service .\n",
      "Tokenised sentence: ['she', 'performed', 'for', 'president', 'reagan', 'in', '1988', \"'\", 's', 'great', 'performances', 'at', 'the', 'white', 'house', 'series', ',', 'which', 'aired', 'on', 'the', 'public', 'broadcasting', 'service', '.']\n",
      "Complex probs: [2.3744050e-04 9.1406476e-01 4.8794089e-05 2.0589681e-02 4.0143383e-01\n",
      " 3.9034574e-05 7.9928734e-04 0.0000000e+00 4.9669971e-04 1.1840747e-03\n",
      " 9.6111482e-01 4.0947019e-05 9.1250113e-05 1.1813736e-03 3.0862011e-03\n",
      " 5.8733761e-01 0.0000000e+00 1.7910992e-04 8.9282066e-01 5.0139373e-05\n",
      " 8.7991160e-05 6.8650488e-03 7.9942781e-01 4.4796746e-03 0.0000000e+00]\n",
      "Binary complexity labels: [0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0]\n",
      "\t Most complex word: performances \n",
      "\n",
      "Found complex word or expression: ### performances ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███▏                                      | 27/359 [05:55<53:03,  9.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['performances', 'performance', 'moments', 'night', 'events']\n",
      "Complex probs: [2.3744050e-04 9.1406476e-01 4.8794089e-05 2.0589681e-02 4.0143383e-01\n",
      " 3.9034574e-05 7.9928734e-04 0.0000000e+00 4.9669971e-04 1.1840747e-03\n",
      " 9.6111482e-01 4.0947019e-05 9.1250113e-05 1.1813736e-03 3.0862011e-03\n",
      " 5.8733761e-01 0.0000000e+00 1.7910992e-04 8.9282066e-01 5.0139373e-05\n",
      " 8.7991160e-05 6.8650488e-03 7.9942781e-01 4.4796746e-03 0.0000000e+00]\n",
      "Binary complexity labels: [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0]\n",
      "\t Most complex word: performed \n",
      "\n",
      "\n",
      "\t Sentence after substitution: she performed for president reagan in 1988 ' s great performances at the white house series , which aired on the public broadcasting service .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: perry saturn  (  with terri  )  defeated eddie guerrero  (  with chyna  )  to win the wwf european championship  (  8 : 10  )  saturn pinned guerrero after a diving elbow drop .\n",
      "Tokenised sentence: ['perry', 'saturn', '(', 'with', 'terri', ')', 'defeated', 'eddie', 'guerrero', '(', 'with', 'chyna', ')', 'to', 'win', 'the', 'wwf', 'european', 'championship', '(', '8', ':', '10', ')', 'saturn', 'pinned', 'guerrero', 'after', 'a', 'diving', 'elbow', 'drop', '.']\n",
      "Complex probs: [4.28439945e-01 2.13383928e-01 0.00000000e+00 6.17847909e-05\n",
      " 7.42273152e-01 0.00000000e+00 4.57062036e-01 4.24930304e-01\n",
      " 6.68748856e-01 0.00000000e+00 4.82954201e-05 0.00000000e+00\n",
      " 0.00000000e+00 5.64544171e-05 3.58287245e-03 9.67803790e-05\n",
      " 7.51287699e-01 1.38702085e-02 8.87924790e-01 0.00000000e+00\n",
      " 7.81713170e-05 0.00000000e+00 1.11630296e-04 0.00000000e+00\n",
      " 7.44159073e-02 3.50280851e-01 7.21226692e-01 7.76300658e-05\n",
      " 9.25304848e-05 5.90363383e-01 5.49768090e-01 1.33515745e-01\n",
      " 0.00000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0]\n",
      "\t Most complex word: championship \n",
      "\n",
      "Found complex word or expression: ### championship ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███                                     | 28/359 [06:11<1:03:40, 11.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['title', 'championship', 'title .', 'championship .', 'cup']\n",
      "Complex probs: [4.3030423e-01 2.1482183e-01 0.0000000e+00 6.2036474e-05 7.4653536e-01\n",
      " 0.0000000e+00 4.6643358e-01 4.3592933e-01 6.7918670e-01 0.0000000e+00\n",
      " 4.9094670e-05 0.0000000e+00 0.0000000e+00 5.8157784e-05 4.3070228e-03\n",
      " 1.0360653e-04 8.0252969e-01 1.6618252e-02 1.2046197e-01 0.0000000e+00\n",
      " 8.1379207e-05 0.0000000e+00 1.1324583e-04 0.0000000e+00 8.3492018e-02\n",
      " 3.8266286e-01 7.4268180e-01 7.7479352e-05 9.4912823e-05 6.1593318e-01\n",
      " 5.5739927e-01 1.3290414e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0]\n",
      "\t Most complex word: wwf \n",
      "\n",
      "\n",
      "\t Sentence after substitution: perry saturn ( with terri ) defeated eddie guerrero ( with chyna ) to win the wwf european title ( 8 : 10 ) saturn pinned guerrero after a diving elbow drop .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: she remained in the united states until 1927 when she and her husband returned to france .\n",
      "Tokenised sentence: ['she', 'remained', 'in', 'the', 'united', 'states', 'until', '1927', 'when', 'she', 'and', 'her', 'husband', 'returned', 'to', 'france', '.']\n",
      "Complex probs: [2.4148777e-04 7.7195275e-01 5.2774878e-05 1.2040553e-04 1.2929562e-02\n",
      " 7.9355488e-04 3.4020952e-04 2.0662933e-03 1.4431764e-04 2.3609327e-04\n",
      " 1.3072528e-04 4.6413078e-04 4.4659015e-02 3.0233726e-01 5.4855103e-05\n",
      " 4.3765446e-03 0.0000000e+00]\n",
      "Binary complexity labels: [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: remained \n",
      "\n",
      "Found complex word or expression: ### remained in the ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███▏                                    | 29/359 [06:32<1:18:57, 14.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['in the', 'in', 'the', 'lived in the', 'lived in']\n",
      "Complex probs: [3.49643349e-04 4.52988352e-05 1.31002438e-04 1.55127635e-02\n",
      " 9.23803542e-04 3.73514573e-04 2.30485434e-03 1.50505119e-04\n",
      " 2.45890784e-04 1.33518639e-04 4.76734189e-04 4.63130847e-02\n",
      " 3.06765527e-01 5.50220175e-05 4.45167115e-03 0.00000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\t Simplificaiton complete or no complex expression found.\n",
      "\n",
      "\n",
      "\t Sentence after substitution: she in the united states until 1927 when she and her husband returned to france .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: despina was discovered in late july , 1989 from the images taken by the voyager 2 probe .\n",
      "Tokenised sentence: ['despina', 'was', 'discovered', 'in', 'late', 'july', ',', '1989', 'from', 'the', 'images', 'taken', 'by', 'the', 'voyager', '2', 'probe', '.']\n",
      "Complex probs: [0.00000000e+00 1.61125819e-04 8.11022520e-01 4.76549176e-05\n",
      " 2.37137266e-03 5.42275002e-03 0.00000000e+00 1.51907804e-03\n",
      " 6.31383300e-05 1.30014465e-04 1.14998534e-01 4.24808497e-03\n",
      " 9.74950963e-05 1.28211817e-04 8.60066235e-01 1.55200803e-04\n",
      " 9.34970319e-01 0.00000000e+00]\n",
      "Binary complexity labels: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "\t Most complex word: probe \n",
      "\n",
      "Found complex word or expression: ### probe ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███▎                                    | 30/359 [06:43<1:13:07, 13.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['probe', 'space probe', 'probes', 'mission', 'orbiter']\n",
      "Complex probs: [0.00000000e+00 1.61125819e-04 8.11022520e-01 4.76549176e-05\n",
      " 2.37137266e-03 5.42275002e-03 0.00000000e+00 1.51907804e-03\n",
      " 6.31383300e-05 1.30014465e-04 1.14998534e-01 4.24808497e-03\n",
      " 9.74950963e-05 1.28211817e-04 8.60066235e-01 1.55200803e-04\n",
      " 9.34970319e-01 0.00000000e+00]\n",
      "Binary complexity labels: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\t Most complex word: voyager \n",
      "\n",
      "\n",
      "\t Sentence after substitution: despina was discovered in late july , 1989 from the images taken by the voyager 2 probe .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: the first italian grand prix motor racing championship took place on 4 september 1921 at brescia .\n",
      "Tokenised sentence: ['the', 'first', 'italian', 'grand', 'prix', 'motor', 'racing', 'championship', 'took', 'place', 'on', '4', 'september', '1921', 'at', 'brescia', '.']\n",
      "Complex probs: [2.3207023e-04 4.5622471e-03 3.2033082e-02 3.6799824e-03 4.2353824e-02\n",
      " 8.0208376e-02 2.6482007e-01 9.6209210e-01 5.6645041e-04 1.5827429e-03\n",
      " 4.3543107e-05 7.6920878e-05 1.9793049e-03 6.9565000e-04 3.5654281e-05\n",
      " 0.0000000e+00 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: championship \n",
      "\n",
      "Found complex word or expression: ### championship ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███▍                                    | 31/359 [06:55<1:12:09, 13.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['event', 'race', 'season', 'event which', 'event . it']\n",
      "Complex probs: [2.4720861e-04 5.1774234e-03 3.6749493e-02 4.2549241e-03 4.8116285e-02\n",
      " 8.4992349e-02 2.5698489e-01 3.6688842e-02 5.1437947e-04 1.9290468e-03\n",
      " 4.5007197e-05 7.9999467e-05 2.2278056e-03 7.4277434e-04 3.6227648e-05\n",
      " 0.0000000e+00 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\t Simplificaiton complete or no complex expression found.\n",
      "\n",
      "\n",
      "\t Sentence after substitution: the first italian grand prix motor racing event took place on 4 september 1921 at brescia .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: he also completed two collections of short stories entitled the ribbajack & other curious yarns and seven strange and ghostly tales .\n",
      "Tokenised sentence: ['he', 'also', 'completed', 'two', 'collections', 'of', 'short', 'stories', 'entitled', 'the', 'ribbajack', '&', 'other', 'curious', 'yarns', 'and', 'seven', 'strange', 'and', 'ghostly', 'tales', '.']\n",
      "Complex probs: [2.3749868e-04 3.8847770e-04 5.0182468e-01 3.1825702e-04 9.4925433e-01\n",
      " 5.8998761e-05 5.5751489e-03 2.4322180e-02 8.2629329e-01 9.6378375e-05\n",
      " 0.0000000e+00 0.0000000e+00 3.6209368e-04 7.1757454e-01 0.0000000e+00\n",
      " 6.1230268e-05 7.9727871e-04 8.1334305e-01 7.3720235e-05 4.9074191e-01\n",
      " 6.8266535e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0]\n",
      "\t Most complex word: collections \n",
      "\n",
      "Found complex word or expression: ### collections of ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███▌                                    | 32/359 [07:10<1:14:32, 13.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['collections of', 'books of', 'collection of', 'volumes of', 'series of']\n",
      "Complex probs: [2.3749868e-04 3.8847770e-04 5.0182468e-01 3.1825702e-04 9.4925433e-01\n",
      " 5.8998761e-05 5.5751489e-03 2.4322180e-02 8.2629329e-01 9.6378375e-05\n",
      " 0.0000000e+00 0.0000000e+00 3.6209368e-04 7.1757454e-01 0.0000000e+00\n",
      " 6.1230268e-05 7.9727871e-04 8.1334305e-01 7.3720235e-05 4.9074191e-01\n",
      " 6.8266535e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0]\n",
      "\t Most complex word: entitled \n",
      "\n",
      "\n",
      "\t Sentence after substitution: he also completed two collections of short stories entitled the ribbajack & other curious yarns and seven strange and ghostly tales .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: at the voyager 2 images ophelia appears as an elongated object , the major axis pointing towards uranus .\n",
      "Tokenised sentence: ['at', 'the', 'voyager', '2', 'images', 'ophelia', 'appears', 'as', 'an', 'elongated', 'object', ',', 'the', 'major', 'axis', 'pointing', 'towards', 'uranus', '.']\n",
      "Complex probs: [4.8879312e-05 8.0735648e-05 7.3236912e-01 1.2710229e-04 6.0595754e-03\n",
      " 0.0000000e+00 5.4737431e-01 6.6726134e-05 1.4474435e-04 8.9088643e-01\n",
      " 3.0199325e-01 0.0000000e+00 6.7564659e-05 7.5032912e-02 8.3558780e-01\n",
      " 3.5648796e-01 2.6796145e-02 0.0000000e+00 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0]\n",
      "\t Most complex word: elongated \n",
      "\n",
      "Found complex word or expression: ### elongated ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███▋                                    | 33/359 [07:29<1:22:58, 15.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['elongated', 'irregular', 'shaped', 'oblate', 'elliptical']\n",
      "Complex probs: [4.8879312e-05 8.0735648e-05 7.3236912e-01 1.2710229e-04 6.0595754e-03\n",
      " 0.0000000e+00 5.4737431e-01 6.6726134e-05 1.4474435e-04 8.9088643e-01\n",
      " 3.0199325e-01 0.0000000e+00 6.7564659e-05 7.5032912e-02 8.3558780e-01\n",
      " 3.5648796e-01 2.6796145e-02 0.0000000e+00 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\t Most complex word: axis \n",
      "\n",
      "\n",
      "\t Sentence after substitution: at the voyager 2 images ophelia appears as an elongated object , the major axis pointing towards uranus .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: the british decided to eliminate him and take the land by force .\n",
      "Tokenised sentence: ['the', 'british', 'decided', 'to', 'eliminate', 'him', 'and', 'take', 'the', 'land', 'by', 'force', '.']\n",
      "Complex probs: [1.4611856e-04 6.3184230e-03 5.3849834e-01 7.3494484e-05 9.1754228e-01\n",
      " 1.8467694e-03 7.9530990e-05 1.1721948e-03 1.4820205e-04 1.8444486e-02\n",
      " 1.2585752e-04 6.9078431e-02 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 1 0 1 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: eliminate \n",
      "\n",
      "Found complex word or expression: ### to eliminate ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███▊                                    | 34/359 [07:51<1:33:03, 17.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['to kill', 'to follow', 'to stop', 'to arrest', 'kill']\n",
      "Complex probs: [1.4437313e-04 6.7909993e-03 5.1208502e-01 6.5688764e-05 1.9643173e-02\n",
      " 2.0107355e-03 9.6515134e-05 1.4640439e-03 1.5930529e-04 2.0549046e-02\n",
      " 1.2777233e-04 7.3025964e-02 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: decided \n",
      "\n",
      "\n",
      "\t Sentence after substitution: the british decided to kill him and take the land by force .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: some towns on the eyre highway in the south - east corner of western australia , between the south australian border almost as far as caiguna , do not follow official western australian time .\n",
      "Tokenised sentence: ['some', 'towns', 'on', 'the', 'eyre', 'highway', 'in', 'the', 'south', '-', 'east', 'corner', 'of', 'western', 'australia', ',', 'between', 'the', 'south', 'australian', 'border', 'almost', 'as', 'far', 'as', 'caiguna', ',', 'do', 'not', 'follow', 'official', 'western', 'australian', 'time', '.']\n",
      "Complex probs: [4.0065503e-04 7.4439988e-02 5.2915279e-05 9.4402829e-05 7.4599874e-01\n",
      " 6.6926926e-02 4.4143580e-05 1.0205871e-04 2.6218684e-03 0.0000000e+00\n",
      " 2.6544353e-03 6.3792878e-01 5.2106923e-05 4.0715276e-03 3.1767131e-03\n",
      " 0.0000000e+00 8.6493696e-05 9.5533549e-05 2.0852904e-03 4.8514776e-02\n",
      " 4.5418981e-02 5.8104102e-03 7.3450632e-05 8.3951512e-03 8.5681328e-05\n",
      " 0.0000000e+00 0.0000000e+00 7.6012897e-05 1.9171168e-04 1.4274794e-01\n",
      " 3.7837231e-01 2.0484398e-03 2.7220499e-02 4.3556123e-04 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: eyre \n",
      "\n",
      "Found complex word or expression: ### eyre ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███▉                                    | 35/359 [08:12<1:39:26, 18.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['eyre', 'stuart', 'great southern', 'kings', 'mitchell']\n",
      "Complex probs: [4.0065503e-04 7.4439988e-02 5.2915279e-05 9.4402829e-05 7.4599874e-01\n",
      " 6.6926926e-02 4.4143580e-05 1.0205871e-04 2.6218684e-03 0.0000000e+00\n",
      " 2.6544353e-03 6.3792878e-01 5.2106923e-05 4.0715276e-03 3.1767131e-03\n",
      " 0.0000000e+00 8.6493696e-05 9.5533549e-05 2.0852904e-03 4.8514776e-02\n",
      " 4.5418981e-02 5.8104102e-03 7.3450632e-05 8.3951512e-03 8.5681328e-05\n",
      " 0.0000000e+00 0.0000000e+00 7.6012897e-05 1.9171168e-04 1.4274794e-01\n",
      " 3.7837231e-01 2.0484398e-03 2.7220499e-02 4.3556123e-04 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: corner \n",
      "\n",
      "\n",
      "\t Sentence after substitution: some towns on the eyre highway in the south - east corner of western australia , between the south australian border almost as far as caiguna , do not follow official western australian time .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: in architectural decoration small pieces of colored and iridescent shell have been used to create mosaics and inlays , which have been used to decorate walls , furniture and boxes .\n",
      "Tokenised sentence: ['in', 'architectural', 'decoration', 'small', 'pieces', 'of', 'colored', 'and', 'iridescent', 'shell', 'have', 'been', 'used', 'to', 'create', 'mosaics', 'and', 'inlays', ',', 'which', 'have', 'been', 'used', 'to', 'decorate', 'walls', ',', 'furniture', 'and', 'boxes', '.']\n",
      "Complex probs: [7.3959782e-05 9.9250799e-01 9.7327697e-01 2.1659052e-03 6.5894514e-02\n",
      " 4.7870766e-05 6.3797450e-01 6.9801710e-05 0.0000000e+00 6.9181949e-01\n",
      " 1.0119109e-04 2.9185353e-04 1.4352362e-03 5.8509802e-05 4.2776659e-02\n",
      " 0.0000000e+00 7.3139730e-05 0.0000000e+00 0.0000000e+00 1.4344919e-04\n",
      " 1.2012891e-04 3.8360234e-04 1.7033273e-03 6.5869346e-05 8.1229258e-01\n",
      " 1.2904354e-02 0.0000000e+00 1.0661177e-01 7.7545570e-05 6.0107064e-01\n",
      " 0.0000000e+00]\n",
      "Binary complexity labels: [0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "\t Most complex word: architectural \n",
      "\n",
      "Found complex word or expression: ### architectural ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████                                    | 36/359 [08:31<1:40:28, 18.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['lay', 'form of', 'geometrical', 'order of', 'architectural']\n",
      "Complex probs: [5.90444106e-05 6.00342810e-01 9.67290461e-01 2.36640777e-03\n",
      " 7.70593584e-02 4.94997221e-05 6.55823886e-01 7.11062021e-05\n",
      " 0.00000000e+00 6.99356496e-01 1.02017155e-04 2.96064391e-04\n",
      " 1.46094500e-03 5.86603092e-05 4.34238836e-02 0.00000000e+00\n",
      " 7.31965338e-05 0.00000000e+00 0.00000000e+00 1.43649595e-04\n",
      " 1.20365228e-04 3.84896499e-04 1.71069650e-03 6.59586076e-05\n",
      " 8.13060820e-01 1.29295997e-02 0.00000000e+00 1.06983140e-01\n",
      " 7.75977969e-05 6.01786077e-01 0.00000000e+00]\n",
      "Binary complexity labels: [0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "\t Most complex word: decoration \n",
      "\n",
      "\n",
      "\t Sentence after substitution: in lay decoration small pieces of colored and iridescent shell have been used to create mosaics and inlays , which have been used to decorate walls , furniture and boxes .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: the other incorporated cities on the palos verdes peninsula include rancho palos verdes , rolling hills estates and rolling hills .\n",
      "Tokenised sentence: ['the', 'other', 'incorporated', 'cities', 'on', 'the', 'palos', 'verdes', 'peninsula', 'include', 'rancho', 'palos', 'verdes', ',', 'rolling', 'hills', 'estates', 'and', 'rolling', 'hills', '.']\n",
      "Complex probs: [1.6136737e-04 9.5901423e-04 9.4375175e-01 3.7040953e-02 4.8186346e-05\n",
      " 8.7364264e-05 0.0000000e+00 0.0000000e+00 8.0559158e-01 4.6685892e-03\n",
      " 5.3937811e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.9295953e-01\n",
      " 2.1427929e-02 5.7250899e-01 6.9617308e-05 5.5450243e-01 4.1689727e-02\n",
      " 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0]\n",
      "\t Most complex word: incorporated \n",
      "\n",
      "Found complex word or expression: ### incorporated ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████                                    | 37/359 [08:37<1:19:18, 14.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['incorporated', 'major', 'small', 'large', 'developed']\n",
      "Complex probs: [1.6136737e-04 9.5901423e-04 9.4375175e-01 3.7040953e-02 4.8186346e-05\n",
      " 8.7364264e-05 0.0000000e+00 0.0000000e+00 8.0559158e-01 4.6685892e-03\n",
      " 5.3937811e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.9295953e-01\n",
      " 2.1427929e-02 5.7250899e-01 6.9617308e-05 5.5450243e-01 4.1689727e-02\n",
      " 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0]\n",
      "\t Most complex word: peninsula \n",
      "\n",
      "\n",
      "\t Sentence after substitution: the other incorporated cities on the palos verdes peninsula include rancho palos verdes , rolling hills estates and rolling hills .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: fearing that drek will destroy the galaxy , clank asks ratchet to help him find the famous superhero captain qwark , in an effort to stop drek .\n",
      "Tokenised sentence: ['fearing', 'that', 'drek', 'will', 'destroy', 'the', 'galaxy', ',', 'clank', 'asks', 'ratchet', 'to', 'help', 'him', 'find', 'the', 'famous', 'superhero', 'captain', 'qwark', ',', 'in', 'an', 'effort', 'to', 'stop', 'drek', '.']\n",
      "Complex probs: [8.63486469e-01 9.94233196e-05 0.00000000e+00 1.09965964e-04\n",
      " 6.69241965e-01 1.01272090e-04 5.01947403e-01 0.00000000e+00\n",
      " 0.00000000e+00 1.19034294e-02 0.00000000e+00 5.68255928e-05\n",
      " 1.66455877e-03 1.08265120e-03 1.58205524e-03 1.34866292e-04\n",
      " 2.31647789e-01 8.59925210e-01 5.51848449e-02 0.00000000e+00\n",
      " 0.00000000e+00 3.32091877e-05 1.25631384e-04 5.98200321e-01\n",
      " 6.25783578e-05 2.31719785e-03 0.00000000e+00 0.00000000e+00]\n",
      "Binary complexity labels: [1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "\t Most complex word: fearing \n",
      "\n",
      "Found complex word or expression: ### fearing that ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████▏                                   | 38/359 [08:50<1:15:53, 14.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['that', 'because', 'thinking that', 'knowing that', 'as']\n",
      "Complex probs: [9.70912370e-05 0.00000000e+00 1.14572715e-04 6.89956486e-01\n",
      " 1.05799576e-04 5.30922651e-01 0.00000000e+00 0.00000000e+00\n",
      " 1.26091484e-02 0.00000000e+00 5.71370620e-05 1.71206670e-03\n",
      " 1.10339443e-03 1.60864717e-03 1.35773909e-04 2.35606581e-01\n",
      " 8.61436486e-01 5.52989431e-02 0.00000000e+00 0.00000000e+00\n",
      " 3.32149211e-05 1.25927414e-04 6.00142717e-01 6.26046749e-05\n",
      " 2.32522353e-03 0.00000000e+00 0.00000000e+00]\n",
      "Binary complexity labels: [0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "\t Most complex word: superhero \n",
      "\n",
      "\n",
      "\t Sentence after substitution: that drek will destroy the galaxy , clank asks ratchet to help him find the famous superhero captain qwark , in an effort to stop drek .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: it is not actually a true louse .\n",
      "Tokenised sentence: ['it', 'is', 'not', 'actually', 'a', 'true', 'louse', '.']\n",
      "Complex probs: [1.5441226e-04 5.0078208e-05 2.0984146e-04 3.9599952e-01 1.4337889e-04\n",
      " 1.8599620e-02 0.0000000e+00 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0]\n",
      "\t Simplificaiton complete or no complex expression found.\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: he advocates applying a user - centered design process in product development cycles and also works towards popularizing interaction design as a mainstream discipline .\n",
      "Tokenised sentence: ['he', 'advocates', 'applying', 'a', 'user', '-', 'centered', 'design', 'process', 'in', 'product', 'development', 'cycles', 'and', 'also', 'works', 'towards', 'popularizing', 'interaction', 'design', 'as', 'a', 'mainstream', 'discipline', '.']\n",
      "Complex probs: [1.6973607e-04 8.2000649e-01 7.3584133e-01 1.1842537e-04 7.4800871e-02\n",
      " 0.0000000e+00 6.3723260e-01 3.0796775e-01 5.0850886e-01 3.8090755e-05\n",
      " 9.2638582e-02 9.1156197e-01 4.8602295e-01 6.0534792e-05 2.2691913e-04\n",
      " 2.7871947e-03 6.4071231e-02 0.0000000e+00 8.3418858e-01 3.2596472e-01\n",
      " 6.1073471e-05 9.4911193e-05 9.1710979e-01 9.4116539e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0]\n",
      "\t Most complex word: discipline \n",
      "\n",
      "Found complex word or expression: ### discipline ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████▋                                     | 40/359 [08:59<51:33,  9.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['discipline', 'practice', 'field', 'subject', 'activity']\n",
      "Complex probs: [1.6973607e-04 8.2000649e-01 7.3584133e-01 1.1842537e-04 7.4800871e-02\n",
      " 0.0000000e+00 6.3723260e-01 3.0796775e-01 5.0850886e-01 3.8090755e-05\n",
      " 9.2638582e-02 9.1156197e-01 4.8602295e-01 6.0534792e-05 2.2691913e-04\n",
      " 2.7871947e-03 6.4071231e-02 0.0000000e+00 8.3418858e-01 3.2596472e-01\n",
      " 6.1073471e-05 9.4911193e-05 9.1710979e-01 9.4116539e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0]\n",
      "\t Most complex word: mainstream \n",
      "\n",
      "\n",
      "\t Sentence after substitution: he advocates applying a user - centered design process in product development cycles and also works towards popularizing interaction design as a mainstream discipline .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: it is theoretically possible that the other editors who may have reported you , and the administrator who blocked you , are part of a conspiracy against someone half a world away they ' ve never met in person .\n",
      "Tokenised sentence: ['it', 'is', 'theoretically', 'possible', 'that', 'the', 'other', 'editors', 'who', 'may', 'have', 'reported', 'you', ',', 'and', 'the', 'administrator', 'who', 'blocked', 'you', ',', 'are', 'part', 'of', 'a', 'conspiracy', 'against', 'someone', 'half', 'a', 'world', 'away', 'they', \"'\", 've', 'never', 'met', 'in', 'person', '.']\n",
      "Complex probs: [1.4544494e-04 5.3094875e-05 9.6190375e-01 1.8647376e-02 6.4970278e-05\n",
      " 9.6283024e-05 1.1359050e-03 1.7759475e-01 1.9246776e-04 1.5416893e-04\n",
      " 1.4735883e-04 2.8973126e-01 1.0041501e-04 0.0000000e+00 5.8368696e-05\n",
      " 8.5783846e-05 9.5203942e-01 1.8857078e-04 1.1793345e-01 8.9882502e-05\n",
      " 0.0000000e+00 5.7054676e-05 6.4713061e-03 4.0762468e-05 9.9180441e-05\n",
      " 9.5987064e-01 2.6896325e-04 1.7045090e-03 2.7827227e-03 1.2412542e-04\n",
      " 1.1163588e-03 1.2771065e-03 1.1288056e-04 0.0000000e+00 6.2819131e-02\n",
      " 1.0078070e-03 7.7911117e-03 4.1037289e-05 5.3945445e-03 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "\t Most complex word: theoretically \n",
      "\n",
      "Found complex word or expression: ### theoretically ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████▊                                     | 41/359 [09:02<43:31,  8.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['quite', 'theoretically', 'equally', 'even', 'only']\n",
      "Complex probs: [1.60078518e-04 4.88974983e-05 6.11490943e-02 1.93569846e-02\n",
      " 7.48152597e-05 1.00453406e-04 1.17435958e-03 1.73377171e-01\n",
      " 1.92903171e-04 1.53168003e-04 1.45841987e-04 2.76852846e-01\n",
      " 1.00046840e-04 0.00000000e+00 5.81344393e-05 8.53969759e-05\n",
      " 9.50291693e-01 1.88335020e-04 1.15880333e-01 8.98634753e-05\n",
      " 0.00000000e+00 5.69638942e-05 6.38724305e-03 4.07166663e-05\n",
      " 9.88462925e-05 9.59229112e-01 2.68969365e-04 1.70033798e-03\n",
      " 2.77077965e-03 1.23929087e-04 1.11275096e-03 1.27251493e-03\n",
      " 1.12760485e-04 0.00000000e+00 6.24185055e-02 1.00628694e-03\n",
      " 7.76738673e-03 4.10094362e-05 5.37502998e-03 0.00000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "\t Most complex word: conspiracy \n",
      "\n",
      "\n",
      "\t Sentence after substitution: it is quite possible that the other editors who may have reported you , and the administrator who blocked you , are part of a conspiracy against someone half a world away they ' ve never met in person .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: working group i : assesses scientific aspects of the climate system and climate change .\n",
      "Tokenised sentence: ['working', 'group', 'i', ':', 'assesses', 'scientific', 'aspects', 'of', 'the', 'climate', 'system', 'and', 'climate', 'change', '.']\n",
      "Complex probs: [1.5392724e-03 1.3502706e-03 6.2349209e-05 0.0000000e+00 0.0000000e+00\n",
      " 8.9331001e-01 6.3304245e-01 3.9312356e-05 6.8099740e-05 7.8899729e-01\n",
      " 7.5010685e-03 6.9949900e-05 8.7672931e-01 9.0881502e-03 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 1 1 0 0 1 0 0 1 0 0]\n",
      "\t Most complex word: scientific \n",
      "\n",
      "Found complex word or expression: ### scientific ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|████▉                                     | 42/359 [09:10<42:34,  8.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['all', 'various', 'the scientific', 'scientific', 'different']\n",
      "Complex probs: [1.6471697e-03 1.5038935e-03 6.1215207e-05 0.0000000e+00 0.0000000e+00\n",
      " 1.7454519e-04 5.9569991e-01 4.1049345e-05 6.9141082e-05 7.8740984e-01\n",
      " 7.9298047e-03 7.0688395e-05 8.7931180e-01 9.3055060e-03 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 1 0 0 1 0 0 1 0 0]\n",
      "\t Most complex word: climate \n",
      "\n",
      "\n",
      "\t Sentence after substitution: working group i : assesses all aspects of the climate system and climate change .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: the island chain forms part of the hebrides , separated from the scottish mainland and from the inner hebrides by the stormy waters of the minch , the little minch and the sea of the hebrides .\n",
      "Tokenised sentence: ['the', 'island', 'chain', 'forms', 'part', 'of', 'the', 'hebrides', ',', 'separated', 'from', 'the', 'scottish', 'mainland', 'and', 'from', 'the', 'inner', 'hebrides', 'by', 'the', 'stormy', 'waters', 'of', 'the', 'minch', ',', 'the', 'little', 'minch', 'and', 'the', 'sea', 'of', 'the', 'hebrides', '.']\n",
      "Complex probs: [1.9374854e-04 3.2261199e-01 2.5914061e-01 2.2567524e-01 7.2712917e-03\n",
      " 4.9984079e-05 1.0210103e-04 0.0000000e+00 0.0000000e+00 8.9071363e-01\n",
      " 7.7670345e-05 1.0208168e-04 4.2967528e-01 7.8972071e-01 9.1172355e-05\n",
      " 6.8964080e-05 1.2328474e-04 6.6385007e-01 0.0000000e+00 1.2041805e-04\n",
      " 1.3206301e-04 8.6810869e-01 1.9841731e-01 4.1527655e-05 8.8553534e-05\n",
      " 0.0000000e+00 0.0000000e+00 7.8404541e-05 1.1930788e-03 0.0000000e+00\n",
      " 9.2606031e-05 1.2483989e-04 3.4914382e-03 4.7328747e-05 9.4867755e-05\n",
      " 0.0000000e+00 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: separated \n",
      "\n",
      "Found complex word or expression: ### separated from the ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|████▊                                   | 43/359 [09:32<1:02:46, 11.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['from the', 'the', 'from', 'off the', 'isolated from the']\n",
      "Complex probs: [2.0118518e-04 3.4374353e-01 2.7779594e-01 2.4242340e-01 7.8216745e-03\n",
      " 5.1274179e-05 1.0915307e-04 0.0000000e+00 0.0000000e+00 6.0438993e-05\n",
      " 1.0848638e-04 4.3222481e-01 8.0128270e-01 9.3808943e-05 7.0537353e-05\n",
      " 1.2698237e-04 6.8364578e-01 0.0000000e+00 1.2159394e-04 1.3422302e-04\n",
      " 8.7281495e-01 2.0172332e-01 4.1565374e-05 8.9075831e-05 0.0000000e+00\n",
      " 0.0000000e+00 7.8626159e-05 1.2048050e-03 0.0000000e+00 9.2744347e-05\n",
      " 1.2514548e-04 3.5150156e-03 4.7339356e-05 9.4949202e-05 0.0000000e+00\n",
      " 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: stormy \n",
      "\n",
      "\n",
      "\t Sentence after substitution: the island chain forms part of the hebrides , from the scottish mainland and from the inner hebrides by the stormy waters of the minch , the little minch and the sea of the hebrides .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: orton and his wife welcomed alanna marie orton on july 12 , 2008 .\n",
      "Tokenised sentence: ['orton', 'and', 'his', 'wife', 'welcomed', 'alanna', 'marie', 'orton', 'on', 'july', '12', ',', '2008', '.']\n",
      "Complex probs: [7.7361876e-01 1.4285976e-04 3.3742888e-04 9.3934024e-03 8.1141186e-01\n",
      " 0.0000000e+00 1.3111210e-02 4.8769340e-01 3.9243962e-05 1.2358752e-03\n",
      " 1.4088149e-04 0.0000000e+00 1.1524272e-03 0.0000000e+00]\n",
      "Binary complexity labels: [1 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: welcomed \n",
      "\n",
      "Found complex word or expression: ### welcomed ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|████▉                                   | 44/359 [09:48<1:07:36, 12.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['dr .', 'and partner', 'welcomed daughter', 'mrs .', 'and daughter']\n",
      "Complex probs: [7.7909452e-01 1.4195121e-04 3.4250563e-04 8.9632319e-03 1.1972289e-01\n",
      " 0.0000000e+00 0.0000000e+00 1.6036542e-02 4.8346677e-01 3.9256614e-05\n",
      " 1.3418243e-03 1.4828573e-04 0.0000000e+00 1.3271511e-03 0.0000000e+00]\n",
      "Binary complexity labels: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: orton \n",
      "\n",
      "\n",
      "\t Sentence after substitution: orton and his wife dr . alanna marie orton on july 12 , 2008 .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: formal minor planet designations are number - name combinations overseen by the minor planet center , a branch of the iau .\n",
      "Tokenised sentence: ['formal', 'minor', 'planet', 'designations', 'are', 'number', '-', 'name', 'combinations', 'overseen', 'by', 'the', 'minor', 'planet', 'center', ',', 'a', 'branch', 'of', 'the', 'iau', '.']\n",
      "Complex probs: [3.8523355e-01 5.5681479e-01 5.7353872e-01 9.6964383e-01 8.1466249e-05\n",
      " 9.9673483e-04 0.0000000e+00 8.6289579e-03 9.2502749e-01 7.9752600e-01\n",
      " 8.3669722e-05 8.6947388e-05 5.7769704e-01 5.1323891e-01 6.3325306e-03\n",
      " 0.0000000e+00 9.2697388e-05 5.7636786e-01 5.2551848e-05 7.8265752e-05\n",
      " 0.0000000e+00 0.0000000e+00]\n",
      "Binary complexity labels: [0 1 1 1 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "\t Most complex word: designations \n",
      "\n",
      "Found complex word or expression: ### designations ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████                                   | 45/359 [10:05<1:14:03, 14.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['names', 'designations', 'naming conventions', 'naming systems', 'names which']\n",
      "Complex probs: [4.6823800e-01 6.6467488e-01 7.0099479e-01 2.7199691e-02 7.4899355e-05\n",
      " 1.4647655e-03 0.0000000e+00 1.0395846e-02 9.3407708e-01 8.1271762e-01\n",
      " 8.4245672e-05 8.8887718e-05 5.9777009e-01 5.2090347e-01 6.3354801e-03\n",
      " 0.0000000e+00 9.3501731e-05 5.8588421e-01 5.2567437e-05 7.8530698e-05\n",
      " 0.0000000e+00 0.0000000e+00]\n",
      "Binary complexity labels: [0 1 1 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "\t Most complex word: combinations \n",
      "\n",
      "\n",
      "\t Sentence after substitution: formal minor planet names are number - name combinations overseen by the minor planet center , a branch of the iau .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: by early on september 30 , wind shear began to dramatically increase and a weakening trend began .\n",
      "Tokenised sentence: ['by', 'early', 'on', 'september', '30', ',', 'wind', 'shear', 'began', 'to', 'dramatically', 'increase', 'and', 'a', 'weakening', 'trend', 'began', '.']\n",
      "Complex probs: [1.47038241e-04 2.82459706e-03 4.82846408e-05 4.06141020e-03\n",
      " 1.35229435e-04 0.00000000e+00 1.40569452e-02 6.49481893e-01\n",
      " 4.74654225e-04 4.72519932e-05 9.61631536e-01 2.14758918e-01\n",
      " 5.97823637e-05 1.03392755e-04 9.58956480e-01 7.29141235e-01\n",
      " 5.64029033e-04 0.00000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0]\n",
      "\t Most complex word: dramatically \n",
      "\n",
      "Found complex word or expression: ### dramatically ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████▏                                  | 46/359 [10:12<1:03:15, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['significantly', 'dramatically', 'steeply', 'rapidly', 'slowly']\n",
      "Complex probs: [1.4766968e-04 2.8578136e-03 4.8469359e-05 4.1107549e-03 1.3589529e-04\n",
      " 0.0000000e+00 1.4132556e-02 6.4800942e-01 4.6713703e-04 4.5452973e-05\n",
      " 9.4713801e-01 2.9591852e-01 6.3630767e-05 1.0553831e-04 9.5904136e-01\n",
      " 7.3095369e-01 5.6835683e-04 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0]\n",
      "\t Most complex word: weakening \n",
      "\n",
      "\n",
      "\t Sentence after substitution: by early on september 30 , wind shear began to significantly increase and a weakening trend began .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: each entry has a datum  (  a nugget of data  )  which is a copy of the datum in some backing store .\n",
      "Tokenised sentence: ['each', 'entry', 'has', 'a', 'datum', '(', 'a', 'nugget', 'of', 'data', ')', 'which', 'is', 'a', 'copy', 'of', 'the', 'datum', 'in', 'some', 'backing', 'store', '.']\n",
      "Complex probs: [3.5730039e-04 7.0273471e-01 1.6467007e-04 1.1372456e-04 0.0000000e+00\n",
      " 0.0000000e+00 1.2495898e-04 0.0000000e+00 4.9416329e-05 4.1912916e-01\n",
      " 0.0000000e+00 2.2113178e-04 4.3597411e-05 1.4021073e-04 2.5912225e-01\n",
      " 5.5472792e-05 9.0600181e-05 0.0000000e+00 5.0061877e-05 1.6553923e-04\n",
      " 5.8215421e-01 2.8943992e-03 0.0000000e+00]\n",
      "Binary complexity labels: [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\t Most complex word: entry \n",
      "\n",
      "Found complex word or expression: ### entry ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████▍                                    | 47/359 [10:17<52:32, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['entry', 'line', 'character', 'item', 'word']\n",
      "Complex probs: [3.5730039e-04 7.0273471e-01 1.6467007e-04 1.1372456e-04 0.0000000e+00\n",
      " 0.0000000e+00 1.2495898e-04 0.0000000e+00 4.9416329e-05 4.1912916e-01\n",
      " 0.0000000e+00 2.2113178e-04 4.3597411e-05 1.4021073e-04 2.5912225e-01\n",
      " 5.5472792e-05 9.0600181e-05 0.0000000e+00 5.0061877e-05 1.6553923e-04\n",
      " 5.8215421e-01 2.8943992e-03 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\t Most complex word: backing \n",
      "\n",
      "\n",
      "\t Sentence after substitution: each entry has a datum ( a nugget of data ) which is a copy of the datum in some backing store .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: as a result , although many mosques will not enforce violations , both men and women when attending a mosque must adhere to these guidelines .\n",
      "Tokenised sentence: ['as', 'a', 'result', ',', 'although', 'many', 'mosques', 'will', 'not', 'enforce', 'violations', ',', 'both', 'men', 'and', 'women', 'when', 'attending', 'a', 'mosque', 'must', 'adhere', 'to', 'these', 'guidelines', '.']\n",
      "Complex probs: [9.4770381e-05 1.2998001e-04 4.1502345e-02 0.0000000e+00 9.7654387e-04\n",
      " 2.7964494e-04 8.2856178e-01 9.6657808e-05 1.6827942e-04 7.5983042e-01\n",
      " 9.1030645e-01 0.0000000e+00 2.5089266e-04 3.8148678e-04 5.1569325e-05\n",
      " 4.0214256e-04 6.1069339e-05 7.0034075e-01 8.3506624e-05 8.2961190e-01\n",
      " 9.5533271e-04 6.6743296e-01 5.6604171e-05 5.5655127e-04 9.3079567e-01\n",
      " 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0]\n",
      "\t Most complex word: guidelines \n",
      "\n",
      "Found complex word or expression: ### guidelines ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████▌                                    | 48/359 [10:21<42:49,  8.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['rules', 'laws', 'guidelines', 'regulations', 'requirements']\n",
      "Complex probs: [9.4770381e-05 1.2994208e-04 4.1516200e-02 0.0000000e+00 9.7656669e-04\n",
      " 2.7983135e-04 8.2860416e-01 9.6765616e-05 1.6870229e-04 7.6013154e-01\n",
      " 9.1032404e-01 0.0000000e+00 2.5199927e-04 3.8389387e-04 5.1713821e-05\n",
      " 4.0545201e-04 6.1522573e-05 7.0240867e-01 8.5498585e-05 8.3485693e-01\n",
      " 1.0777921e-03 6.7843533e-01 6.0637583e-05 6.3043984e-04 8.8019170e-02\n",
      " 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0]\n",
      "\t Most complex word: violations \n",
      "\n",
      "\n",
      "\t Sentence after substitution: as a result , although many mosques will not enforce violations , both men and women when attending a mosque must adhere to these rules .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: mariel of redwall is a fantasy novel by brian jacques , published in 1991 .\n",
      "Tokenised sentence: ['mariel', 'of', 'redwall', 'is', 'a', 'fantasy', 'novel', 'by', 'brian', 'jacques', ',', 'published', 'in', '1991', '.']\n",
      "Complex probs: [0.0000000e+00 5.8604281e-05 0.0000000e+00 5.4780659e-05 1.3010412e-04\n",
      " 8.2040513e-01 8.6284816e-01 9.4428491e-05 2.4162700e-02 6.4132255e-01\n",
      " 0.0000000e+00 8.6759871e-01 3.5937886e-05 6.5801892e-04 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 1 1 0 0 1 0 1 0 0 0]\n",
      "\t Most complex word: published \n",
      "\n",
      "Found complex word or expression: ### published in ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████▋                                    | 49/359 [10:39<56:52, 11.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['published in', 'published', 'written in', 'originally published in', 'in']\n",
      "Complex probs: [0.0000000e+00 5.8604281e-05 0.0000000e+00 5.4780659e-05 1.3010412e-04\n",
      " 8.2040513e-01 8.6284816e-01 9.4428491e-05 2.4162700e-02 6.4132255e-01\n",
      " 0.0000000e+00 8.6759871e-01 3.5937886e-05 6.5801892e-04 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 1 1 0 0 1 0 0 0 0 0]\n",
      "\t Most complex word: novel \n",
      "\n",
      "\n",
      "\t Sentence after substitution: mariel of redwall is a fantasy novel by brian jacques , published in 1991 .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: ryan prosser  (  born 10 july , 1988  )  is a professional rugby union player for bristol rugby in the guinness premiership .\n",
      "Tokenised sentence: ['ryan', 'prosser', '(', 'born', '10', 'july', ',', '1988', ')', 'is', 'a', 'professional', 'rugby', 'union', 'player', 'for', 'bristol', 'rugby', 'in', 'the', 'guinness', 'premiership', '.']\n",
      "Complex probs: [4.41764370e-02 0.00000000e+00 0.00000000e+00 1.22975716e-02\n",
      " 1.06809115e-04 1.73169363e-03 0.00000000e+00 6.84920698e-04\n",
      " 0.00000000e+00 4.96758184e-05 1.25816616e-04 9.43691015e-01\n",
      " 6.96824431e-01 6.31639585e-02 4.84146997e-02 4.13484086e-05\n",
      " 6.42725155e-02 6.53864980e-01 3.87502441e-05 8.09186167e-05\n",
      " 7.56030500e-01 9.18264806e-01 0.00000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 0]\n",
      "\t Most complex word: professional \n",
      "\n",
      "Found complex word or expression: ### a professional ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████▌                                  | 50/359 [10:56<1:05:34, 12.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['a', 'a professional', 'an american', 'an english', 'an american professional']\n",
      "Complex probs: [4.6501242e-02 0.0000000e+00 0.0000000e+00 1.2924700e-02 1.0881345e-04\n",
      " 1.8047412e-03 0.0000000e+00 7.1266876e-04 0.0000000e+00 5.0076251e-05\n",
      " 1.2441823e-04 7.6476890e-01 1.2095082e-01 6.2349267e-02 4.2400989e-05\n",
      " 6.8386622e-02 6.6994858e-01 3.9038445e-05 8.2245177e-05 7.6668268e-01\n",
      " 9.2064905e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0]\n",
      "\t Most complex word: premiership \n",
      "\n",
      "\n",
      "\t Sentence after substitution: ryan prosser ( born 10 july , 1988 ) is a rugby union player for bristol rugby in the guinness premiership .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: like previous assessment reports , it consists of four reports , three of them from its working groups .\n",
      "Tokenised sentence: ['like', 'previous', 'assessment', 'reports', ',', 'it', 'consists', 'of', 'four', 'reports', ',', 'three', 'of', 'them', 'from', 'its', 'working', 'groups', '.']\n",
      "Complex probs: [4.2288180e-04 5.5798119e-01 9.4464272e-01 1.4463873e-02 0.0000000e+00\n",
      " 8.8350425e-05 7.6311785e-01 5.5863075e-05 2.8357902e-04 8.8198585e-03\n",
      " 0.0000000e+00 2.5714957e-04 5.2386731e-05 6.6009507e-04 6.7217632e-05\n",
      " 2.9177146e-04 3.0951092e-03 2.7608041e-02 0.0000000e+00]\n",
      "Binary complexity labels: [0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: assessment \n",
      "\n",
      "Found complex word or expression: ### assessment ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████▋                                  | 51/359 [11:11<1:08:55, 13.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['research', 'report', 'management', 'annual', 'study']\n",
      "Complex probs: [4.4409581e-04 5.8232403e-01 7.5598371e-01 1.1483094e-02 0.0000000e+00\n",
      " 8.8899826e-05 7.7151120e-01 5.6499925e-05 2.8944135e-04 9.2215780e-03\n",
      " 0.0000000e+00 2.6254504e-04 5.2846295e-05 6.7390624e-04 6.7735498e-05\n",
      " 2.9562379e-04 3.1559905e-03 2.8106369e-02 0.0000000e+00]\n",
      "Binary complexity labels: [0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: consists \n",
      "\n",
      "\n",
      "\t Sentence after substitution: like previous research reports , it consists of four reports , three of them from its working groups .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: their granddaughter hélène langevin - joliot is a professor of nuclear physics at the university of paris , and their grandson pierre joliot , who was named after pierre curie , is a noted biochemist .\n",
      "Tokenised sentence: ['their', 'granddaughter', 'helene', 'langevin', '-', 'joliot', 'is', 'a', 'professor', 'of', 'nuclear', 'physics', 'at', 'the', 'university', 'of', 'paris', ',', 'and', 'their', 'grandson', 'pierre', 'joliot', ',', 'who', 'was', 'named', 'after', 'pierre', 'curie', ',', 'is', 'a', 'noted', 'biochemist', '.']\n",
      "Complex probs: [2.4108587e-04 9.4701064e-01 3.0327439e-01 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 4.5392975e-05 1.3093089e-04 4.2872214e-01 4.7055568e-05\n",
      " 1.0685381e-01 8.5241902e-01 3.8588983e-05 7.2605217e-05 6.8556778e-02\n",
      " 4.1811498e-05 4.3716561e-03 0.0000000e+00 6.8387119e-05 1.7811295e-04\n",
      " 8.5491186e-01 6.2602448e-01 0.0000000e+00 0.0000000e+00 1.4596984e-04\n",
      " 1.0135604e-04 1.3289660e-02 8.9009598e-05 5.4861546e-01 0.0000000e+00\n",
      " 0.0000000e+00 3.9679886e-05 1.3094349e-04 2.1980226e-02 0.0000000e+00\n",
      " 0.0000000e+00]\n",
      "Binary complexity labels: [0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\t Most complex word: granddaughter \n",
      "\n",
      "Found complex word or expression: ### granddaughter ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████▊                                  | 52/359 [11:19<1:01:07, 11.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['daughter', 'granddaughter', 'grand daughter', 'sister', 'youngest daughter']\n",
      "Complex probs: [2.3854875e-04 3.4394238e-02 4.5742011e-01 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 4.5753171e-05 1.3728798e-04 4.6252590e-01 4.7566296e-05\n",
      " 1.1661996e-01 8.6031127e-01 3.8721286e-05 7.3633244e-05 7.2083160e-02\n",
      " 4.2059481e-05 4.4983798e-03 0.0000000e+00 6.8924368e-05 1.8021606e-04\n",
      " 8.5859686e-01 6.2817049e-01 0.0000000e+00 0.0000000e+00 1.4653703e-04\n",
      " 1.0164330e-04 1.3402116e-02 8.9195171e-05 5.5086523e-01 0.0000000e+00\n",
      " 0.0000000e+00 3.9704493e-05 1.3117706e-04 2.2080243e-02 0.0000000e+00\n",
      " 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\t Most complex word: physics \n",
      "\n",
      "\n",
      "\t Sentence after substitution: their daughter helene langevin - joliot is a professor of nuclear physics at the university of paris , and their grandson pierre joliot , who was named after pierre curie , is a noted biochemist .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: this stamp remained the standard letter stamp for the remainder of victoria ' s reign , and vast quantities were printed .\n",
      "Tokenised sentence: ['this', 'stamp', 'remained', 'the', 'standard', 'letter', 'stamp', 'for', 'the', 'remainder', 'of', 'victoria', \"'\", 's', 'reign', ',', 'and', 'vast', 'quantities', 'were', 'printed', '.']\n",
      "Complex probs: [1.36362316e-04 7.82037914e-01 8.34156811e-01 1.13532034e-04\n",
      " 2.58336235e-02 8.21690559e-02 8.26784790e-01 4.96674802e-05\n",
      " 1.11838497e-04 8.61369491e-01 5.38580680e-05 2.77847759e-02\n",
      " 0.00000000e+00 3.04127840e-04 5.96904039e-01 0.00000000e+00\n",
      " 7.20758981e-05 9.55624521e-01 8.93898189e-01 7.30887041e-05\n",
      " 7.50841737e-01 0.00000000e+00]\n",
      "Binary complexity labels: [0 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 1 0 1 0]\n",
      "\t Most complex word: vast \n",
      "\n",
      "Found complex word or expression: ### and vast ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█████▉                                  | 53/359 [11:41<1:15:57, 14.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['and', 'and large', 'although smaller', 'though smaller', 'but']\n",
      "Complex probs: [1.36941773e-04 7.83830941e-01 8.36472511e-01 1.14371855e-04\n",
      " 2.64501646e-02 8.39483365e-02 8.29703093e-01 5.01008035e-05\n",
      " 1.13391921e-04 8.64798188e-01 5.41726477e-05 2.99847554e-02\n",
      " 0.00000000e+00 3.14080506e-04 6.12008333e-01 0.00000000e+00\n",
      " 7.09619926e-05 9.47590053e-01 9.02803004e-05 7.52902627e-01\n",
      " 0.00000000e+00]\n",
      "Binary complexity labels: [0 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0]\n",
      "\t Most complex word: quantities \n",
      "\n",
      "\n",
      "\t Sentence after substitution: this stamp remained the standard letter stamp for the remainder of victoria ' s reign , and quantities were printed .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: the international fight league was an american mixed martial arts  (  mma  )  promotion billed as the world ' s first mma league .\n",
      "Tokenised sentence: ['the', 'international', 'fight', 'league', 'was', 'an', 'american', 'mixed', 'martial', 'arts', '(', 'mma', ')', 'promotion', 'billed', 'as', 'the', 'world', \"'\", 's', 'first', 'mma', 'league', '.']\n",
      "Complex probs: [1.66060636e-04 8.90416324e-01 1.21924160e-02 8.88719559e-01\n",
      " 1.13723916e-04 1.83251381e-04 1.79462635e-03 8.35990757e-02\n",
      " 6.57862008e-01 2.43424755e-02 0.00000000e+00 4.93887782e-01\n",
      " 0.00000000e+00 6.77435160e-01 7.89605200e-01 6.94649716e-05\n",
      " 1.03591017e-04 7.97526445e-04 0.00000000e+00 3.48070607e-04\n",
      " 7.22010212e-04 6.73555434e-01 8.67887735e-01 0.00000000e+00]\n",
      "Binary complexity labels: [0 1 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0]\n",
      "\t Most complex word: international \n",
      "\n",
      "Found complex word or expression: ### the international ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|██████                                  | 54/359 [11:57<1:16:57, 15.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['the world', 'or the', 'the ultimate', 'the', 'the first']\n",
      "Complex probs: [1.58349678e-04 6.49227470e-04 5.01084514e-03 9.08347845e-01\n",
      " 1.20083801e-04 1.91124898e-04 1.89628743e-03 8.97819400e-02\n",
      " 6.72435224e-01 2.48345323e-02 0.00000000e+00 4.99553859e-01\n",
      " 0.00000000e+00 6.79810643e-01 7.90941596e-01 6.92546455e-05\n",
      " 1.03891056e-04 8.01336893e-04 0.00000000e+00 3.49233916e-04\n",
      " 7.26439059e-04 6.76054776e-01 8.68392646e-01 0.00000000e+00]\n",
      "Binary complexity labels: [0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0]\n",
      "\t Most complex word: league \n",
      "\n",
      "\n",
      "\t Sentence after substitution: the world fight league was an american mixed martial arts ( mma ) promotion billed as the world ' s first mma league .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: giardia lamblia  (  synonymous with lamblia intestinalis and giardia duodenalis  )  is a flagellated protozoan parasite that colonises and reproduces in the small intestine , causing giardiasis .\n",
      "Tokenised sentence: ['giardia', 'lamblia', '(', 'synonymous', 'with', 'lamblia', 'intestinalis', 'and', 'giardia', 'duodenalis', ')', 'is', 'a', 'flagellated', 'protozoan', 'parasite', 'that', 'colonises', 'and', 'reproduces', 'in', 'the', 'small', 'intestine', ',', 'causing', 'giardiasis', '.']\n",
      "Complex probs: [0.0000000e+00 0.0000000e+00 0.0000000e+00 9.1938949e-01 5.2139134e-05\n",
      " 0.0000000e+00 0.0000000e+00 6.2566483e-05 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 4.1408464e-05 9.7627300e-05 0.0000000e+00 0.0000000e+00\n",
      " 9.3815178e-01 7.6435586e-05 0.0000000e+00 7.5277851e-05 0.0000000e+00\n",
      " 3.9654427e-05 7.0505354e-05 1.6908079e-03 0.0000000e+00 0.0000000e+00\n",
      " 3.7533186e-02 0.0000000e+00 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: parasite \n",
      "\n",
      "Found complex word or expression: ### parasite ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|██████▏                                 | 55/359 [12:06<1:07:49, 13.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['species', 'cete', 'in nature', 'parasite', 'of origin']\n",
      "Complex probs: [0.0000000e+00 0.0000000e+00 0.0000000e+00 9.1894424e-01 5.2020980e-05\n",
      " 0.0000000e+00 0.0000000e+00 6.2501837e-05 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 4.1503426e-05 1.0129797e-04 0.0000000e+00 0.0000000e+00\n",
      " 8.4659827e-01 7.1005590e-05 0.0000000e+00 7.5977252e-05 0.0000000e+00\n",
      " 3.9558156e-05 7.1067916e-05 1.7438402e-03 0.0000000e+00 0.0000000e+00\n",
      " 3.8832508e-02 0.0000000e+00 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: synonymous \n",
      "\n",
      "\n",
      "\t Sentence after substitution: giardia lamblia ( synonymous with lamblia intestinalis and giardia duodenalis ) is a flagellated protozoan species that colonises and reproduces in the small intestine , causing giardiasis .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: aside from this , cameron has often worked in christian - themed productions , among them the post - rapture films left behind : the movie , left behind ii : tribulation force , and left behind : world at war , in which he plays cameron \" buck \" williams .\n",
      "Tokenised sentence: ['aside', 'from', 'this', ',', 'cameron', 'has', 'often', 'worked', 'in', 'christian', '-', 'themed', 'productions', ',', 'among', 'them', 'the', 'post', '-', 'rapture', 'films', 'left', 'behind', ':', 'the', 'movie', ',', 'left', 'behind', 'ii', ':', 'tribulation', 'force', ',', 'and', 'left', 'behind', ':', 'world', 'at', 'war', ',', 'in', 'which', 'he', 'plays', 'cameron', '\"', 'buck', '\"', 'williams', '.']\n",
      "Complex probs: [8.8695943e-01 9.5114039e-05 1.2325370e-04 0.0000000e+00 2.9132754e-02\n",
      " 1.3205508e-04 1.0451986e-03 1.3319795e-02 4.3598076e-05 1.1008276e-01\n",
      " 0.0000000e+00 6.4879709e-01 9.0445065e-01 0.0000000e+00 5.5325456e-04\n",
      " 4.1896876e-04 8.5647502e-05 3.9544538e-02 0.0000000e+00 0.0000000e+00\n",
      " 5.5734384e-01 2.8689194e-03 9.7385322e-04 0.0000000e+00 1.1318882e-04\n",
      " 2.0837408e-02 0.0000000e+00 2.1388684e-03 1.0011252e-03 2.4836159e-03\n",
      " 0.0000000e+00 0.0000000e+00 1.2497788e-02 0.0000000e+00 6.0355305e-05\n",
      " 3.6066384e-03 9.9374913e-04 0.0000000e+00 6.8908266e-04 2.9771467e-05\n",
      " 1.0952756e-03 0.0000000e+00 3.4427947e-05 2.0695121e-04 1.5880118e-04\n",
      " 6.2745926e-03 4.2611413e-02 0.0000000e+00 7.2680339e-02 0.0000000e+00\n",
      " 1.5937269e-02 0.0000000e+00]\n",
      "Binary complexity labels: [1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: productions \n",
      "\n",
      "Found complex word or expression: ### productions ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|██████▌                                   | 56/359 [12:13<58:43, 11.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['productions', 'projects', 'films', 'works', 'media']\n",
      "Complex probs: [8.8695943e-01 9.5114039e-05 1.2325370e-04 0.0000000e+00 2.9132754e-02\n",
      " 1.3205508e-04 1.0451986e-03 1.3319795e-02 4.3598076e-05 1.1008276e-01\n",
      " 0.0000000e+00 6.4879709e-01 9.0445065e-01 0.0000000e+00 5.5325456e-04\n",
      " 4.1896876e-04 8.5647502e-05 3.9544538e-02 0.0000000e+00 0.0000000e+00\n",
      " 5.5734384e-01 2.8689194e-03 9.7385322e-04 0.0000000e+00 1.1318882e-04\n",
      " 2.0837408e-02 0.0000000e+00 2.1388684e-03 1.0011252e-03 2.4836159e-03\n",
      " 0.0000000e+00 0.0000000e+00 1.2497788e-02 0.0000000e+00 6.0355305e-05\n",
      " 3.6066384e-03 9.9374913e-04 0.0000000e+00 6.8908266e-04 2.9771467e-05\n",
      " 1.0952756e-03 0.0000000e+00 3.4427947e-05 2.0695121e-04 1.5880118e-04\n",
      " 6.2745926e-03 4.2611413e-02 0.0000000e+00 7.2680339e-02 0.0000000e+00\n",
      " 1.5937269e-02 0.0000000e+00]\n",
      "Binary complexity labels: [1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: aside \n",
      "\n",
      "\n",
      "\t Sentence after substitution: aside from this , cameron has often worked in christian - themed productions , among them the post - rapture films left behind : the movie , left behind ii : tribulation force , and left behind : world at war , in which he plays cameron \" buck \" williams .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: this was the area east of the mouth of the vistula river , later sometimes called \" prussia proper \" .\n",
      "Tokenised sentence: ['this', 'was', 'the', 'area', 'east', 'of', 'the', 'mouth', 'of', 'the', 'vistula', 'river', ',', 'later', 'sometimes', 'called', '\"', 'prussia', 'proper', '\"', '.']\n",
      "Complex probs: [1.7151609e-04 1.4222258e-04 1.5726974e-04 1.9020442e-02 5.8464259e-03\n",
      " 4.6515812e-05 1.0188318e-04 4.3331170e-01 5.4435925e-05 9.3045433e-05\n",
      " 0.0000000e+00 1.5109667e-02 0.0000000e+00 6.7404564e-04 5.1998603e-03\n",
      " 9.6915569e-04 0.0000000e+00 8.1981236e-01 2.8422233e-01 0.0000000e+00\n",
      " 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\t Most complex word: prussia \n",
      "\n",
      "Found complex word or expression: ### prussia ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|██████▎                                 | 57/359 [12:32<1:08:24, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['poland', 'prussia', 'warsaw', 'east prussia', 'germany']\n",
      "Complex probs: [1.7340865e-04 1.4404311e-04 1.5948449e-04 1.9604770e-02 6.0319155e-03\n",
      " 4.7118887e-05 1.0388986e-04 4.4707391e-01 5.5576624e-05 9.5731077e-05\n",
      " 0.0000000e+00 1.6443131e-02 0.0000000e+00 7.2523206e-04 6.0166712e-03\n",
      " 1.0435749e-03 0.0000000e+00 9.6106865e-03 2.8010067e-01 0.0000000e+00\n",
      " 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\t Simplificaiton complete or no complex expression found.\n",
      "\n",
      "\n",
      "\t Sentence after substitution: this was the area east of the mouth of the vistula river , later sometimes called \" poland proper \" .\n",
      "\n",
      "Untokenised sentence: after graduation he returned to yerevan to teach at the local conservatory and later he was appointed artistic director of the armenian philarmonic orchestra .\n",
      "Tokenised sentence: ['after', 'graduation', 'he', 'returned', 'to', 'yerevan', 'to', 'teach', 'at', 'the', 'local', 'conservatory', 'and', 'later', 'he', 'was', 'appointed', 'artistic', 'director', 'of', 'the', 'armenian', 'philarmonic', 'orchestra', '.']\n",
      "Complex probs: [1.3755755e-04 9.4285589e-01 1.6031666e-04 2.6976797e-01 6.6859378e-05\n",
      " 8.4819406e-01 7.2673931e-05 8.4781927e-01 4.0292973e-05 8.0305348e-05\n",
      " 2.0399748e-03 9.4923127e-01 7.5541764e-05 7.4992399e-04 1.6415853e-04\n",
      " 1.3526050e-04 9.7676623e-01 9.6203804e-01 2.6697347e-01 3.8169117e-05\n",
      " 8.0835642e-05 5.6436503e-01 0.0000000e+00 7.3534787e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 1 0]\n",
      "\t Most complex word: appointed \n",
      "\n",
      "Found complex word or expression: ### he was appointed ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|██████▍                                 | 58/359 [12:48<1:11:39, 14.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['became', 'as', 'became the', 'was', 'as the']\n",
      "Complex probs: [1.3851443e-04 9.4446450e-01 1.6125679e-04 2.7294219e-01 6.7242254e-05\n",
      " 8.5305184e-01 7.2938587e-05 8.5203201e-01 4.0572053e-05 7.9767968e-05\n",
      " 1.8367175e-03 9.4971526e-01 7.5219432e-05 6.6519843e-04 1.0886146e-03\n",
      " 9.7010851e-01 3.4108096e-01 3.8929065e-05 8.2481980e-05 5.9940028e-01\n",
      " 0.0000000e+00 7.5396997e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0]\n",
      "\t Most complex word: artistic \n",
      "\n",
      "\n",
      "\t Sentence after substitution: after graduation he returned to yerevan to teach at the local conservatory and later became artistic director of the armenian philarmonic orchestra .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: the story of christmas is based on the biblical accounts given in the gospel of matthew , namely  -  and the gospel of luke , specifically  -  .\n",
      "Tokenised sentence: ['the', 'story', 'of', 'christmas', 'is', 'based', 'on', 'the', 'biblical', 'accounts', 'given', 'in', 'the', 'gospel', 'of', 'matthew', ',', 'namely', '-', 'and', 'the', 'gospel', 'of', 'luke', ',', 'specifically', '-', '.']\n",
      "Complex probs: [1.9086650e-04 1.7928019e-02 5.8077978e-05 8.4399275e-02 5.6219425e-05\n",
      " 7.4719124e-02 5.5642435e-05 8.7550747e-05 8.1082749e-01 5.8476210e-01\n",
      " 3.5174165e-03 3.8702310e-05 9.5496929e-05 7.5184995e-01 5.4368120e-05\n",
      " 5.8608335e-01 0.0000000e+00 4.4356209e-01 0.0000000e+00 6.3810039e-05\n",
      " 8.6794127e-05 7.1043658e-01 5.3023577e-05 5.1282978e-01 0.0000000e+00\n",
      " 9.5770150e-01 0.0000000e+00 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0]\n",
      "\t Most complex word: specifically \n",
      "\n",
      "Found complex word or expression: ### specifically ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|██████▌                                 | 59/359 [12:58<1:05:44, 13.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['namely', 'specifically', 'that is', 'also namely', 'such as']\n",
      "Complex probs: [1.9097590e-04 1.7988889e-02 5.8148911e-05 8.4785990e-02 5.6313114e-05\n",
      " 7.5026676e-02 5.5776527e-05 8.7720640e-05 8.1210542e-01 5.8720642e-01\n",
      " 3.5508822e-03 3.8827773e-05 9.6037009e-05 7.5483483e-01 5.4614371e-05\n",
      " 5.9147131e-01 0.0000000e+00 4.5062780e-01 0.0000000e+00 6.4219639e-05\n",
      " 8.7249544e-05 7.0596099e-01 5.2907002e-05 5.0286913e-01 0.0000000e+00\n",
      " 4.4129890e-01 0.0000000e+00 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0]\n",
      "\t Most complex word: biblical \n",
      "\n",
      "\n",
      "\t Sentence after substitution: the story of christmas is based on the biblical accounts given in the gospel of matthew , namely - and the gospel of luke , namely - .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: weelkes was later to find himself in trouble with the chichester cathedral authorities for his heavy drinking and immoderate behaviour .\n",
      "Tokenised sentence: ['weelkes', 'was', 'later', 'to', 'find', 'himself', 'in', 'trouble', 'with', 'the', 'chichester', 'cathedral', 'authorities', 'for', 'his', 'heavy', 'drinking', 'and', 'immoderate', 'behaviour', '.']\n",
      "Complex probs: [0.0000000e+00 1.5032584e-04 1.4287654e-03 6.8978814e-05 2.1887189e-03\n",
      " 1.5689623e-02 4.5297886e-05 5.6031120e-01 4.4490127e-05 8.7040789e-05\n",
      " 8.2447052e-01 9.1301388e-01 9.0804416e-01 3.9784085e-05 2.2738523e-04\n",
      " 3.5343304e-02 7.3084217e-01 6.4974054e-05 0.0000000e+00 9.2670697e-01\n",
      " 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 0]\n",
      "\t Most complex word: behaviour \n",
      "\n",
      "Found complex word or expression: ### behaviour ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|███████                                   | 60/359 [13:05<56:37, 11.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['behaviour', 'behavior', 'manner', 'nature', 'habits']\n",
      "Complex probs: [0.0000000e+00 1.5032584e-04 1.4287654e-03 6.8978814e-05 2.1887189e-03\n",
      " 1.5689623e-02 4.5297886e-05 5.6031120e-01 4.4490127e-05 8.7040789e-05\n",
      " 8.2447052e-01 9.1301388e-01 9.0804416e-01 3.9784085e-05 2.2738523e-04\n",
      " 3.5343304e-02 7.3084217e-01 6.4974054e-05 0.0000000e+00 9.2670697e-01\n",
      " 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 0 0 0 0]\n",
      "\t Most complex word: cathedral \n",
      "\n",
      "\n",
      "\t Sentence after substitution: weelkes was later to find himself in trouble with the chichester cathedral authorities for his heavy drinking and immoderate behaviour .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: so far the ' celebrity ' episodes have included vic reeves , nancy sorrell , gaby roslin , scott mills , mark chapman , simon gregson , sue cleaver , carol thatcher , paul o ' grady and lee ryan .\n",
      "Tokenised sentence: ['so', 'far', 'the', \"'\", 'celebrity', \"'\", 'episodes', 'have', 'included', 'vic', 'reeves', ',', 'nancy', 'sorrell', ',', 'gaby', 'roslin', ',', 'scott', 'mills', ',', 'mark', 'chapman', ',', 'simon', 'gregson', ',', 'sue', 'cleaver', ',', 'carol', 'thatcher', ',', 'paul', 'o', \"'\", 'grady', 'and', 'lee', 'ryan', '.']\n",
      "Complex probs: [2.1229204e-04 3.0007986e-03 1.1531200e-04 0.0000000e+00 7.6276916e-01\n",
      " 0.0000000e+00 8.8603002e-01 1.3778503e-04 6.8837322e-02 6.5560341e-01\n",
      " 6.9598985e-01 0.0000000e+00 5.2771842e-01 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.7212301e-01 3.2001591e-01\n",
      " 0.0000000e+00 4.1170889e-03 6.1439896e-01 0.0000000e+00 3.8240772e-01\n",
      " 0.0000000e+00 0.0000000e+00 4.9810195e-01 0.0000000e+00 0.0000000e+00\n",
      " 4.1222215e-01 5.0267047e-01 0.0000000e+00 8.1321126e-04 1.0898012e-03\n",
      " 0.0000000e+00 4.4975126e-01 6.9606285e-05 2.2061134e-02 3.9575193e-02\n",
      " 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0]\n",
      "\t Most complex word: episodes \n",
      "\n",
      "Found complex word or expression: ### episodes ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|███████▏                                  | 61/359 [13:13<51:22, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['guests', 'members', 'episodes', 'series', 'shows']\n",
      "Complex probs: [2.0951721e-04 2.9507929e-03 1.1322455e-04 0.0000000e+00 7.4123573e-01\n",
      " 0.0000000e+00 4.3112162e-01 1.3000901e-04 6.5053068e-02 6.4324832e-01\n",
      " 6.9485134e-01 0.0000000e+00 5.2878821e-01 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.7368143e-01 3.2111537e-01\n",
      " 0.0000000e+00 4.1242605e-03 6.1457711e-01 0.0000000e+00 3.8236108e-01\n",
      " 0.0000000e+00 0.0000000e+00 4.9802673e-01 0.0000000e+00 0.0000000e+00\n",
      " 4.1223758e-01 5.0265837e-01 0.0000000e+00 8.1284088e-04 1.0894960e-03\n",
      " 0.0000000e+00 4.4962776e-01 6.9603499e-05 2.2051906e-02 3.9573327e-02\n",
      " 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0]\n",
      "\t Most complex word: celebrity \n",
      "\n",
      "\n",
      "\t Sentence after substitution: so far the ' celebrity ' guests have included vic reeves , nancy sorrell , gaby roslin , scott mills , mark chapman , simon gregson , sue cleaver , carol thatcher , paul o ' grady and lee ryan .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: it was discovered by stephen p . synnott in images from the voyager 1 space probe taken on march 5 , 1979 while orbiting around jupiter .\n",
      "Tokenised sentence: ['it', 'was', 'discovered', 'by', 'stephen', 'p', '.', 'synnott', 'in', 'images', 'from', 'the', 'voyager', '1', 'space', 'probe', 'taken', 'on', 'march', '5', ',', '1979', 'while', 'orbiting', 'around', 'jupiter', '.']\n",
      "Complex probs: [1.8757390e-04 1.4234064e-04 8.4968668e-01 1.2331881e-04 1.1693531e-01\n",
      " 1.5866283e-03 0.0000000e+00 0.0000000e+00 4.9832965e-05 2.5693072e-02\n",
      " 6.0612030e-05 9.1966780e-05 7.2250289e-01 1.1301023e-04 1.7083983e-03\n",
      " 9.4085723e-01 1.7310583e-03 3.8545808e-05 1.3336514e-03 7.2957373e-05\n",
      " 0.0000000e+00 5.6701328e-04 1.1817225e-04 6.5672386e-01 2.8397457e-04\n",
      " 8.9599961e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0]\n",
      "\t Most complex word: probe \n",
      "\n",
      "Found complex word or expression: ### probe ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|███████▎                                  | 62/359 [13:25<53:04, 10.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['probe', 'station', 'port', 'drive', 'camera']\n",
      "Complex probs: [1.8757390e-04 1.4234064e-04 8.4968668e-01 1.2331881e-04 1.1693531e-01\n",
      " 1.5866283e-03 0.0000000e+00 0.0000000e+00 4.9832965e-05 2.5693072e-02\n",
      " 6.0612030e-05 9.1966780e-05 7.2250289e-01 1.1301023e-04 1.7083983e-03\n",
      " 9.4085723e-01 1.7310583e-03 3.8545808e-05 1.3336514e-03 7.2957373e-05\n",
      " 0.0000000e+00 5.6701328e-04 1.1817225e-04 6.5672386e-01 2.8397457e-04\n",
      " 8.9599961e-01 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "\t Most complex word: jupiter \n",
      "\n",
      "\n",
      "\t Sentence after substitution: it was discovered by stephen p . synnott in images from the voyager 1 space probe taken on march 5 , 1979 while orbiting around jupiter .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: gomaespuma was a spanish radio show , hosted by juan luis cano and guillermo fesser .\n",
      "Tokenised sentence: ['gomaespuma', 'was', 'a', 'spanish', 'radio', 'show', ',', 'hosted', 'by', 'juan', 'luis', 'cano', 'and', 'guillermo', 'fesser', '.']\n",
      "Complex probs: [0.0000000e+00 1.3644659e-04 1.4923155e-04 1.9569870e-03 6.4171463e-02\n",
      " 1.3012629e-03 0.0000000e+00 7.3544574e-01 8.8925357e-05 4.3500531e-01\n",
      " 7.3844912e-03 0.0000000e+00 6.2377047e-05 8.3071613e-01 0.0000000e+00\n",
      " 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0]\n",
      "\t Most complex word: guillermo \n",
      "\n",
      "Found complex word or expression: ### guillermo ###. Plainifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|███████▎                                  | 63/359 [13:40<59:12, 12.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested top 5 subtitutions: ['david', 'daniel', 'martin', 'antonio', 'jose']\n",
      "Complex probs: [0.0000000e+00 1.3716068e-04 1.5043223e-04 1.9905458e-03 6.5261573e-02\n",
      " 1.3293126e-03 0.0000000e+00 7.3482317e-01 8.9545007e-05 4.3780208e-01\n",
      " 7.7768848e-03 0.0000000e+00 6.0020051e-05 1.0415611e-03 0.0000000e+00\n",
      " 0.0000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\t Most complex word: hosted \n",
      "\n",
      "\n",
      "\t Sentence after substitution: gomaespuma was a spanish radio show , hosted by juan luis cano and david fesser .\n",
      "\n",
      "Simplification complete.\r",
      "Untokenised sentence: on 16 june 2009 , the official release date of the resistance was announced on the band ' s website .\n",
      "Tokenised sentence: ['on', '16', 'june', '2009', ',', 'the', 'official', 'release', 'date', 'of', 'the', 'resistance', 'was', 'announced', 'on', 'the', 'band', \"'\", 's', 'website', '.']\n",
      "Complex probs: [5.84098998e-05 1.06421154e-04 9.47877765e-04 1.16671575e-03\n",
      " 0.00000000e+00 8.75847254e-05 3.68308634e-01 2.38194004e-01\n",
      " 3.35282013e-02 4.43442441e-05 1.01979407e-04 9.72130120e-01\n",
      " 1.27746011e-04 9.50755179e-01 5.21069705e-05 8.08652549e-05\n",
      " 1.63450077e-01 0.00000000e+00 3.19156126e-04 1.76586390e-01\n",
      " 0.00000000e+00]\n",
      "Binary complexity labels: [0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0]\n",
      "\t Most complex word: resistance \n",
      "\n",
      "Found complex word or expression: ### the resistance ###. Plainifying...\n"
     ]
    }
   ],
   "source": [
    "# Read Test Data\n",
    "norm_test_dat = ReadInFile(\"./evaluation/WikiLargeTurkCorpus/test.8turkers.tok.norm\")\n",
    "\n",
    "sentence = []\n",
    "for i in tqdm(range(len(norm_test_dat))):\n",
    "    input_sentence = norm_test_dat[i]\n",
    "\n",
    "    s = ComplexSentence(input_sentence, label_model=Complexity_labeller_model, tokeniser=tokenizer, verbose=True)\n",
    "    sentence.append(s.recursive_greedy_plainify(max_steps=2))\n",
    "              \n",
    "with codecs.open(\"test.output\", \"w\", \"utf-8-sig\") as f:\n",
    "    for item in sentence:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ed7efe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7208be6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
